{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration cakiki--gutenberg-poetry-corpus-7745b6aecdad34dc\n",
      "Found cached dataset parquet (C:/Users/Shayne Kaiser/.cache/huggingface/datasets/biglam___parquet/cakiki--gutenberg-poetry-corpus-7745b6aecdad34dc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(\"biglam/gutenberg-poetry-corpus\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['line', 'gutenberg_id'],\n",
       "    num_rows: 3085117\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Pandas\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (3085117, 2)\n"
     ]
    }
   ],
   "source": [
    "print('df shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Song of Hiawatha is based on the legends a...\n",
       "1    many North American Indian tribes, but especia...\n",
       "2    Ojibway Indians of northern Michigan, Wisconsi...\n",
       "3    They were collected by Henry Rowe Schoolcraft,...\n",
       "4    Schoolcraft married Jane, O-bah-bahm-wawa-ge-z...\n",
       "Name: line, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = df[\"line\"]\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        for txt in txt_list:\n",
    "            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation=True,\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating text \n",
    "def generate_from_model(model, tokenizer, prompt, max_length=300, temp=1.5, num_outputs=10):\n",
    "    \"\"\"\n",
    "    Tokenize the given prompt, must be one string, and generate output from a  provided model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        mondel (transformers.model): The model being used to generate text\n",
    "        tokenizer: the tokenizer being used\n",
    "        prompt (str): The input string that is used to generate text\n",
    "        max_length (int): Max character length of the generated outputs\n",
    "        temp (int): Set the temperature for the outputs\n",
    "        num_outputs (int): number of different outputs to be created\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\"Outputs for: \" + prompt)\n",
    "\n",
    "    generated = tokenizer(\"<|startoftext|> \" + prompt, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    sample_outputs = model.generate(generated, max_length=max_length, do_sample=True, top_p=0.95, top_k=50, temperature=temp, num_return_sequences=num_outputs)\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilGPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model\n",
    "torch.manual_seed(92)\n",
    "\n",
    "MODEL_NAME = \"distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./Models/DistilGPT2', num_train_epochs=1, logging_steps=10000, save_steps=50000,\n",
    "                                  per_device_train_batch_size=10, per_device_eval_batch_size=10, warmup_steps=10,\n",
    "                                   weight_decay=0.05, logging_dir='./Models/DistilGPT2/logs', report_to='none' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(tokenizer.encode(line)) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization_dataset = PoetryDataset(lines, tokenizer, max_length=max_length)\n",
    "train_size = int(0.9  * len(tokenization_dataset))\n",
    "train_dataset, val_dataset = random_split(tokenization_dataset, [train_size, len(tokenization_dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50257,   818,   262,  7032,   262,   302,   521, 28153,  4836,   606,\n",
       "         11496, 50256, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training dataset: 2776605\n",
      "Length of Validation dataset: 308512\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of Training dataset: {len(train_dataset)}\")\n",
    "print(f\"Length of Validation dataset: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight True\n",
      "transformer.wpe.weight True\n",
      "transformer.h.0.ln_1.weight True\n",
      "transformer.h.0.ln_1.bias True\n",
      "transformer.h.0.attn.c_attn.weight True\n",
      "transformer.h.0.attn.c_attn.bias True\n",
      "transformer.h.0.attn.c_proj.weight True\n",
      "transformer.h.0.attn.c_proj.bias True\n",
      "transformer.h.0.ln_2.weight True\n",
      "transformer.h.0.ln_2.bias True\n",
      "transformer.h.0.mlp.c_fc.weight True\n",
      "transformer.h.0.mlp.c_fc.bias True\n",
      "transformer.h.0.mlp.c_proj.weight True\n",
      "transformer.h.0.mlp.c_proj.bias True\n",
      "transformer.h.1.ln_1.weight True\n",
      "transformer.h.1.ln_1.bias True\n",
      "transformer.h.1.attn.c_attn.weight True\n",
      "transformer.h.1.attn.c_attn.bias True\n",
      "transformer.h.1.attn.c_proj.weight True\n",
      "transformer.h.1.attn.c_proj.bias True\n",
      "transformer.h.1.ln_2.weight True\n",
      "transformer.h.1.ln_2.bias True\n",
      "transformer.h.1.mlp.c_fc.weight True\n",
      "transformer.h.1.mlp.c_fc.bias True\n",
      "transformer.h.1.mlp.c_proj.weight True\n",
      "transformer.h.1.mlp.c_proj.bias True\n",
      "transformer.h.2.ln_1.weight True\n",
      "transformer.h.2.ln_1.bias True\n",
      "transformer.h.2.attn.c_attn.weight True\n",
      "transformer.h.2.attn.c_attn.bias True\n",
      "transformer.h.2.attn.c_proj.weight True\n",
      "transformer.h.2.attn.c_proj.bias True\n",
      "transformer.h.2.ln_2.weight True\n",
      "transformer.h.2.ln_2.bias True\n",
      "transformer.h.2.mlp.c_fc.weight True\n",
      "transformer.h.2.mlp.c_fc.bias True\n",
      "transformer.h.2.mlp.c_proj.weight True\n",
      "transformer.h.2.mlp.c_proj.bias True\n",
      "transformer.h.3.ln_1.weight True\n",
      "transformer.h.3.ln_1.bias True\n",
      "transformer.h.3.attn.c_attn.weight True\n",
      "transformer.h.3.attn.c_attn.bias True\n",
      "transformer.h.3.attn.c_proj.weight True\n",
      "transformer.h.3.attn.c_proj.bias True\n",
      "transformer.h.3.ln_2.weight True\n",
      "transformer.h.3.ln_2.bias True\n",
      "transformer.h.3.mlp.c_fc.weight True\n",
      "transformer.h.3.mlp.c_fc.bias True\n",
      "transformer.h.3.mlp.c_proj.weight True\n",
      "transformer.h.3.mlp.c_proj.bias True\n",
      "transformer.h.4.ln_1.weight True\n",
      "transformer.h.4.ln_1.bias True\n",
      "transformer.h.4.attn.c_attn.weight True\n",
      "transformer.h.4.attn.c_attn.bias True\n",
      "transformer.h.4.attn.c_proj.weight True\n",
      "transformer.h.4.attn.c_proj.bias True\n",
      "transformer.h.4.ln_2.weight True\n",
      "transformer.h.4.ln_2.bias True\n",
      "transformer.h.4.mlp.c_fc.weight True\n",
      "transformer.h.4.mlp.c_fc.bias True\n",
      "transformer.h.4.mlp.c_proj.weight True\n",
      "transformer.h.4.mlp.c_proj.bias True\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.c_attn.weight True\n",
      "transformer.h.5.attn.c_attn.bias True\n",
      "transformer.h.5.attn.c_proj.weight True\n",
      "transformer.h.5.attn.c_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "# check layers in the model\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the first two layers and 4 hidden units\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"transformer.wte\"):\n",
    "        param.requires_grad = False\n",
    "    if name.startswith(\"transformer.wpe\"):\n",
    "        param.requires_grad = False\n",
    "    if any(x in name for x in ['.' + str(x) + '.' for x in range(5)]):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight False\n",
      "transformer.wpe.weight False\n",
      "transformer.h.0.ln_1.weight False\n",
      "transformer.h.0.ln_1.bias False\n",
      "transformer.h.0.attn.c_attn.weight False\n",
      "transformer.h.0.attn.c_attn.bias False\n",
      "transformer.h.0.attn.c_proj.weight False\n",
      "transformer.h.0.attn.c_proj.bias False\n",
      "transformer.h.0.ln_2.weight False\n",
      "transformer.h.0.ln_2.bias False\n",
      "transformer.h.0.mlp.c_fc.weight False\n",
      "transformer.h.0.mlp.c_fc.bias False\n",
      "transformer.h.0.mlp.c_proj.weight False\n",
      "transformer.h.0.mlp.c_proj.bias False\n",
      "transformer.h.1.ln_1.weight False\n",
      "transformer.h.1.ln_1.bias False\n",
      "transformer.h.1.attn.c_attn.weight False\n",
      "transformer.h.1.attn.c_attn.bias False\n",
      "transformer.h.1.attn.c_proj.weight False\n",
      "transformer.h.1.attn.c_proj.bias False\n",
      "transformer.h.1.ln_2.weight False\n",
      "transformer.h.1.ln_2.bias False\n",
      "transformer.h.1.mlp.c_fc.weight False\n",
      "transformer.h.1.mlp.c_fc.bias False\n",
      "transformer.h.1.mlp.c_proj.weight False\n",
      "transformer.h.1.mlp.c_proj.bias False\n",
      "transformer.h.2.ln_1.weight False\n",
      "transformer.h.2.ln_1.bias False\n",
      "transformer.h.2.attn.c_attn.weight False\n",
      "transformer.h.2.attn.c_attn.bias False\n",
      "transformer.h.2.attn.c_proj.weight False\n",
      "transformer.h.2.attn.c_proj.bias False\n",
      "transformer.h.2.ln_2.weight False\n",
      "transformer.h.2.ln_2.bias False\n",
      "transformer.h.2.mlp.c_fc.weight False\n",
      "transformer.h.2.mlp.c_fc.bias False\n",
      "transformer.h.2.mlp.c_proj.weight False\n",
      "transformer.h.2.mlp.c_proj.bias False\n",
      "transformer.h.3.ln_1.weight False\n",
      "transformer.h.3.ln_1.bias False\n",
      "transformer.h.3.attn.c_attn.weight False\n",
      "transformer.h.3.attn.c_attn.bias False\n",
      "transformer.h.3.attn.c_proj.weight False\n",
      "transformer.h.3.attn.c_proj.bias False\n",
      "transformer.h.3.ln_2.weight False\n",
      "transformer.h.3.ln_2.bias False\n",
      "transformer.h.3.mlp.c_fc.weight False\n",
      "transformer.h.3.mlp.c_fc.bias False\n",
      "transformer.h.3.mlp.c_proj.weight False\n",
      "transformer.h.3.mlp.c_proj.bias False\n",
      "transformer.h.4.ln_1.weight False\n",
      "transformer.h.4.ln_1.bias False\n",
      "transformer.h.4.attn.c_attn.weight False\n",
      "transformer.h.4.attn.c_attn.bias False\n",
      "transformer.h.4.attn.c_proj.weight False\n",
      "transformer.h.4.attn.c_proj.bias False\n",
      "transformer.h.4.ln_2.weight False\n",
      "transformer.h.4.ln_2.bias False\n",
      "transformer.h.4.mlp.c_fc.weight False\n",
      "transformer.h.4.mlp.c_fc.bias False\n",
      "transformer.h.4.mlp.c_proj.weight False\n",
      "transformer.h.4.mlp.c_proj.bias False\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.c_attn.weight True\n",
      "transformer.h.5.attn.c_attn.bias True\n",
      "transformer.h.5.attn.c_proj.weight True\n",
      "transformer.h.5.attn.c_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "# now check layers\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shayne Kaiser\\anaconda3\\envs\\poetryproject\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2776605\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 277661\n",
      "  Number of trainable parameters = 7089408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c2548f192042ec9759ccb1fdc69b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7205, 'learning_rate': 4.8200978926782185e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6612, 'learning_rate': 4.640015703166925e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6561, 'learning_rate': 4.459933513655633e-05, 'epoch': 0.11}\n",
      "{'loss': 0.651, 'learning_rate': 4.27985132414434e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-50000\n",
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-50000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6485, 'learning_rate': 4.099769134633047e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-50000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6451, 'learning_rate': 3.919686945121754e-05, 'epoch': 0.22}\n",
      "{'loss': 0.6437, 'learning_rate': 3.739604755610461e-05, 'epoch': 0.25}\n",
      "{'loss': 0.6417, 'learning_rate': 3.559522566099168e-05, 'epoch': 0.29}\n",
      "{'loss': 0.6399, 'learning_rate': 3.3794403765878745e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6389, 'learning_rate': 3.199358187076582e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-100000\\config.json\n",
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-100000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6379, 'learning_rate': 3.019275997565289e-05, 'epoch': 0.4}\n",
      "{'loss': 0.6369, 'learning_rate': 2.839193808053996e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6371, 'learning_rate': 2.659111618542703e-05, 'epoch': 0.47}\n",
      "{'loss': 0.6361, 'learning_rate': 2.47902942903141e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-150000\n",
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-150000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6335, 'learning_rate': 2.298947239520117e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-150000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6334, 'learning_rate': 2.118865050008824e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6331, 'learning_rate': 1.938782860497531e-05, 'epoch': 0.61}\n",
      "{'loss': 0.6335, 'learning_rate': 1.7587006709862385e-05, 'epoch': 0.65}\n",
      "{'loss': 0.6317, 'learning_rate': 1.5786184814749453e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6318, 'learning_rate': 1.3985362919636521e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-200000\\config.json\n",
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-200000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.632, 'learning_rate': 1.2184541024523593e-05, 'epoch': 0.76}\n",
      "{'loss': 0.6321, 'learning_rate': 1.0383719129410665e-05, 'epoch': 0.79}\n",
      "{'loss': 0.6297, 'learning_rate': 8.582897234297733e-06, 'epoch': 0.83}\n",
      "{'loss': 0.6309, 'learning_rate': 6.782075339184804e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-250000\n",
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-250000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6308, 'learning_rate': 4.981253444071874e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-250000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6302, 'learning_rate': 3.1804315489589452e-06, 'epoch': 0.94}\n",
      "{'loss': 0.63, 'learning_rate': 1.3796096538460155e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 11295.2762, 'train_samples_per_second': 245.82, 'train_steps_per_second': 24.582, 'train_loss': 0.6407216623165254, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=277661, training_loss=0.6407216623165254, metrics={'train_runtime': 11295.2762, 'train_samples_per_second': 245.82, 'train_steps_per_second': 24.582, 'train_loss': 0.6407216623165254, 'epoch': 1.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n",
    "        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0] for f in data])}).train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/DistilGPT2\\config.json\n",
      "Model weights saved in ./Models/DistilGPT2\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save model and Tokenizer\n",
    "model.save_pretrained(\"./Models/DistilGPT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./Models/DistilGPT2\\tokenizer_config.json\n",
      "Special tokens file saved in ./Models/DistilGPT2\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Models/DistilGPT2\\\\tokenizer_config.json',\n",
       " './Models/DistilGPT2\\\\special_tokens_map.json',\n",
       " './Models/DistilGPT2\\\\vocab.json',\n",
       " './Models/DistilGPT2\\\\merges.txt',\n",
       " './Models/DistilGPT2\\\\added_tokens.json',\n",
       " './Models/DistilGPT2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./Models/DistilGPT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file ./Models/DistilGPT2\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"./Models/DistilGPT2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50259\n",
      "}\n",
      "\n",
      "loading weights file ./Models/DistilGPT2\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./Models/DistilGPT2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load in saved model and tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Models/DistilGPT2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./Models/DistilGPT2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: In view of the fading animals\n",
      "0:  In view of the fading animals\n",
      "1:  In view of the fading animals which\n",
      "2:  In view of the fading animals, I will only live for the\n",
      "3:  In view of the fading animals at its tail,\n",
      "4:  In view of the fading animals\n",
      "5:  In view of the fading animals the little flock of young,\n",
      "6:  In view of the fading animals.\n",
      "7:  In view of the fading animals\n",
      "8:  In view of the fading animals who wander and flee.\n",
      "9:  In view of the fading animals and the lost;\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"In view of the fading animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Shall I compare thee\n",
      "0:  Shall I compare thee in some respect not so\n",
      "1:  Shall I compare thee, with his art so dark\n",
      "2:  Shall I compare thee and the other?\n",
      "3:  Shall I compare thee, and tell his son to look in thee!\n",
      "4:  Shall I compare thee?\n",
      "5:  Shall I compare thee to me;\n",
      "6:  Shall I compare thee with thee\n",
      "7:  Shall I compare thee; and then shall thou see\n",
      "8:  Shall I compare thee more thy grace and my good,\n",
      "9:  Shall I compare thee for my son,\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"Shall I compare thee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness\n",
      "0:  Deep into that darkness beneath his heart!\n",
      "1:  Deep into that darkness in that bright hour, we knew\n",
      "2:  Deep into that darkness lay: the night of darkness on us to be\n",
      "3:  Deep into that darkness; a dream of life\n",
      "4:  Deep into that darkness,\n",
      "5:  Deep into that darkness he saw no face. No voice\n",
      "6:  Deep into that darkness, where the long night\n",
      "7:  Deep into that darkness his soul in the night falls;\n",
      "8:  Deep into that darkness lay its dark abyss;\n",
      "9:  Deep into that darkness they may not lie so long,\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"Deep into that darkness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "0:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I,\n",
      "1:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "2:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "3:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "4:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "5:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I.\n",
      "6:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "7:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "8:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "9:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n"
     ]
    }
   ],
   "source": [
    "long_prompt = 'Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I'\n",
    "\n",
    "generate_from_model(model, tokenizer, long_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: I stay\n",
      "0:  I stay too late to get away\n",
      "1:  I stay, in my arms the wind,\n",
      "2:  I stay to do his duty.\n",
      "3:  I stay awake on nights long,\n",
      "4:  I stay up for a day alone to have\n",
      "5:  I stay--no longer, no more?--you don't have much to think:\n",
      "6:  I stay so old and strong as a child,\n",
      "7:  I stay true to the man I loved--\n",
      "8:  I stay for nights, I pray till I see my Father--\n",
      "9:  I stay but never leave it, it shall always be,\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"I stay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model\n",
    "torch.manual_seed(92)\n",
    "\n",
    "MODEL_NAME = \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "tokenizer_neo = AutoTokenizer.from_pretrained(MODEL_NAME, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "model_neo = AutoModelForCausalLM.from_pretrained(MODEL_NAME).cuda()\n",
    "model_neo.resize_token_embeddings(len(tokenizer_neo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing arguments\n",
    "training_args_neo = TrainingArguments(output_dir='./Models/GPT-Neo', num_train_epochs=1, logging_steps=10000, save_steps=500000,\n",
    "                                  per_device_train_batch_size=10, per_device_eval_batch_size=10, warmup_steps=10,\n",
    "                                   weight_decay=0.05, logging_dir='./Models/GPT-Neo/logs', report_to='none' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(tokenizer_neo.encode(line)) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization_dataset = PoetryDataset(lines, tokenizer_neo, max_length=max_length)\n",
    "train_size = int(0.9  * len(tokenization_dataset))\n",
    "train_dataset_neo, val_dataset_neo = random_split(tokenization_dataset, [train_size, len(tokenization_dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50257,  3152,   257,  9480,  2786,   273,    11,   543,    11,   996,\n",
       "           284,   262,  4151, 50256, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_neo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training dataset: 2776605\n",
      "Length of Validation dataset: 308512\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of Training dataset: {len(train_dataset_neo)}\")\n",
    "print(f\"Length of Validation dataset: {len(val_dataset_neo)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight True\n",
      "transformer.wpe.weight True\n",
      "transformer.h.0.ln_1.weight True\n",
      "transformer.h.0.ln_1.bias True\n",
      "transformer.h.0.attn.attention.k_proj.weight True\n",
      "transformer.h.0.attn.attention.v_proj.weight True\n",
      "transformer.h.0.attn.attention.q_proj.weight True\n",
      "transformer.h.0.attn.attention.out_proj.weight True\n",
      "transformer.h.0.attn.attention.out_proj.bias True\n",
      "transformer.h.0.ln_2.weight True\n",
      "transformer.h.0.ln_2.bias True\n",
      "transformer.h.0.mlp.c_fc.weight True\n",
      "transformer.h.0.mlp.c_fc.bias True\n",
      "transformer.h.0.mlp.c_proj.weight True\n",
      "transformer.h.0.mlp.c_proj.bias True\n",
      "transformer.h.1.ln_1.weight True\n",
      "transformer.h.1.ln_1.bias True\n",
      "transformer.h.1.attn.attention.k_proj.weight True\n",
      "transformer.h.1.attn.attention.v_proj.weight True\n",
      "transformer.h.1.attn.attention.q_proj.weight True\n",
      "transformer.h.1.attn.attention.out_proj.weight True\n",
      "transformer.h.1.attn.attention.out_proj.bias True\n",
      "transformer.h.1.ln_2.weight True\n",
      "transformer.h.1.ln_2.bias True\n",
      "transformer.h.1.mlp.c_fc.weight True\n",
      "transformer.h.1.mlp.c_fc.bias True\n",
      "transformer.h.1.mlp.c_proj.weight True\n",
      "transformer.h.1.mlp.c_proj.bias True\n",
      "transformer.h.2.ln_1.weight True\n",
      "transformer.h.2.ln_1.bias True\n",
      "transformer.h.2.attn.attention.k_proj.weight True\n",
      "transformer.h.2.attn.attention.v_proj.weight True\n",
      "transformer.h.2.attn.attention.q_proj.weight True\n",
      "transformer.h.2.attn.attention.out_proj.weight True\n",
      "transformer.h.2.attn.attention.out_proj.bias True\n",
      "transformer.h.2.ln_2.weight True\n",
      "transformer.h.2.ln_2.bias True\n",
      "transformer.h.2.mlp.c_fc.weight True\n",
      "transformer.h.2.mlp.c_fc.bias True\n",
      "transformer.h.2.mlp.c_proj.weight True\n",
      "transformer.h.2.mlp.c_proj.bias True\n",
      "transformer.h.3.ln_1.weight True\n",
      "transformer.h.3.ln_1.bias True\n",
      "transformer.h.3.attn.attention.k_proj.weight True\n",
      "transformer.h.3.attn.attention.v_proj.weight True\n",
      "transformer.h.3.attn.attention.q_proj.weight True\n",
      "transformer.h.3.attn.attention.out_proj.weight True\n",
      "transformer.h.3.attn.attention.out_proj.bias True\n",
      "transformer.h.3.ln_2.weight True\n",
      "transformer.h.3.ln_2.bias True\n",
      "transformer.h.3.mlp.c_fc.weight True\n",
      "transformer.h.3.mlp.c_fc.bias True\n",
      "transformer.h.3.mlp.c_proj.weight True\n",
      "transformer.h.3.mlp.c_proj.bias True\n",
      "transformer.h.4.ln_1.weight True\n",
      "transformer.h.4.ln_1.bias True\n",
      "transformer.h.4.attn.attention.k_proj.weight True\n",
      "transformer.h.4.attn.attention.v_proj.weight True\n",
      "transformer.h.4.attn.attention.q_proj.weight True\n",
      "transformer.h.4.attn.attention.out_proj.weight True\n",
      "transformer.h.4.attn.attention.out_proj.bias True\n",
      "transformer.h.4.ln_2.weight True\n",
      "transformer.h.4.ln_2.bias True\n",
      "transformer.h.4.mlp.c_fc.weight True\n",
      "transformer.h.4.mlp.c_fc.bias True\n",
      "transformer.h.4.mlp.c_proj.weight True\n",
      "transformer.h.4.mlp.c_proj.bias True\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.attention.k_proj.weight True\n",
      "transformer.h.5.attn.attention.v_proj.weight True\n",
      "transformer.h.5.attn.attention.q_proj.weight True\n",
      "transformer.h.5.attn.attention.out_proj.weight True\n",
      "transformer.h.5.attn.attention.out_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.h.6.ln_1.weight True\n",
      "transformer.h.6.ln_1.bias True\n",
      "transformer.h.6.attn.attention.k_proj.weight True\n",
      "transformer.h.6.attn.attention.v_proj.weight True\n",
      "transformer.h.6.attn.attention.q_proj.weight True\n",
      "transformer.h.6.attn.attention.out_proj.weight True\n",
      "transformer.h.6.attn.attention.out_proj.bias True\n",
      "transformer.h.6.ln_2.weight True\n",
      "transformer.h.6.ln_2.bias True\n",
      "transformer.h.6.mlp.c_fc.weight True\n",
      "transformer.h.6.mlp.c_fc.bias True\n",
      "transformer.h.6.mlp.c_proj.weight True\n",
      "transformer.h.6.mlp.c_proj.bias True\n",
      "transformer.h.7.ln_1.weight True\n",
      "transformer.h.7.ln_1.bias True\n",
      "transformer.h.7.attn.attention.k_proj.weight True\n",
      "transformer.h.7.attn.attention.v_proj.weight True\n",
      "transformer.h.7.attn.attention.q_proj.weight True\n",
      "transformer.h.7.attn.attention.out_proj.weight True\n",
      "transformer.h.7.attn.attention.out_proj.bias True\n",
      "transformer.h.7.ln_2.weight True\n",
      "transformer.h.7.ln_2.bias True\n",
      "transformer.h.7.mlp.c_fc.weight True\n",
      "transformer.h.7.mlp.c_fc.bias True\n",
      "transformer.h.7.mlp.c_proj.weight True\n",
      "transformer.h.7.mlp.c_proj.bias True\n",
      "transformer.h.8.ln_1.weight True\n",
      "transformer.h.8.ln_1.bias True\n",
      "transformer.h.8.attn.attention.k_proj.weight True\n",
      "transformer.h.8.attn.attention.v_proj.weight True\n",
      "transformer.h.8.attn.attention.q_proj.weight True\n",
      "transformer.h.8.attn.attention.out_proj.weight True\n",
      "transformer.h.8.attn.attention.out_proj.bias True\n",
      "transformer.h.8.ln_2.weight True\n",
      "transformer.h.8.ln_2.bias True\n",
      "transformer.h.8.mlp.c_fc.weight True\n",
      "transformer.h.8.mlp.c_fc.bias True\n",
      "transformer.h.8.mlp.c_proj.weight True\n",
      "transformer.h.8.mlp.c_proj.bias True\n",
      "transformer.h.9.ln_1.weight True\n",
      "transformer.h.9.ln_1.bias True\n",
      "transformer.h.9.attn.attention.k_proj.weight True\n",
      "transformer.h.9.attn.attention.v_proj.weight True\n",
      "transformer.h.9.attn.attention.q_proj.weight True\n",
      "transformer.h.9.attn.attention.out_proj.weight True\n",
      "transformer.h.9.attn.attention.out_proj.bias True\n",
      "transformer.h.9.ln_2.weight True\n",
      "transformer.h.9.ln_2.bias True\n",
      "transformer.h.9.mlp.c_fc.weight True\n",
      "transformer.h.9.mlp.c_fc.bias True\n",
      "transformer.h.9.mlp.c_proj.weight True\n",
      "transformer.h.9.mlp.c_proj.bias True\n",
      "transformer.h.10.ln_1.weight True\n",
      "transformer.h.10.ln_1.bias True\n",
      "transformer.h.10.attn.attention.k_proj.weight True\n",
      "transformer.h.10.attn.attention.v_proj.weight True\n",
      "transformer.h.10.attn.attention.q_proj.weight True\n",
      "transformer.h.10.attn.attention.out_proj.weight True\n",
      "transformer.h.10.attn.attention.out_proj.bias True\n",
      "transformer.h.10.ln_2.weight True\n",
      "transformer.h.10.ln_2.bias True\n",
      "transformer.h.10.mlp.c_fc.weight True\n",
      "transformer.h.10.mlp.c_fc.bias True\n",
      "transformer.h.10.mlp.c_proj.weight True\n",
      "transformer.h.10.mlp.c_proj.bias True\n",
      "transformer.h.11.ln_1.weight True\n",
      "transformer.h.11.ln_1.bias True\n",
      "transformer.h.11.attn.attention.k_proj.weight True\n",
      "transformer.h.11.attn.attention.v_proj.weight True\n",
      "transformer.h.11.attn.attention.q_proj.weight True\n",
      "transformer.h.11.attn.attention.out_proj.weight True\n",
      "transformer.h.11.attn.attention.out_proj.bias True\n",
      "transformer.h.11.ln_2.weight True\n",
      "transformer.h.11.ln_2.bias True\n",
      "transformer.h.11.mlp.c_fc.weight True\n",
      "transformer.h.11.mlp.c_fc.bias True\n",
      "transformer.h.11.mlp.c_proj.weight True\n",
      "transformer.h.11.mlp.c_proj.bias True\n",
      "transformer.h.12.ln_1.weight True\n",
      "transformer.h.12.ln_1.bias True\n",
      "transformer.h.12.attn.attention.k_proj.weight True\n",
      "transformer.h.12.attn.attention.v_proj.weight True\n",
      "transformer.h.12.attn.attention.q_proj.weight True\n",
      "transformer.h.12.attn.attention.out_proj.weight True\n",
      "transformer.h.12.attn.attention.out_proj.bias True\n",
      "transformer.h.12.ln_2.weight True\n",
      "transformer.h.12.ln_2.bias True\n",
      "transformer.h.12.mlp.c_fc.weight True\n",
      "transformer.h.12.mlp.c_fc.bias True\n",
      "transformer.h.12.mlp.c_proj.weight True\n",
      "transformer.h.12.mlp.c_proj.bias True\n",
      "transformer.h.13.ln_1.weight True\n",
      "transformer.h.13.ln_1.bias True\n",
      "transformer.h.13.attn.attention.k_proj.weight True\n",
      "transformer.h.13.attn.attention.v_proj.weight True\n",
      "transformer.h.13.attn.attention.q_proj.weight True\n",
      "transformer.h.13.attn.attention.out_proj.weight True\n",
      "transformer.h.13.attn.attention.out_proj.bias True\n",
      "transformer.h.13.ln_2.weight True\n",
      "transformer.h.13.ln_2.bias True\n",
      "transformer.h.13.mlp.c_fc.weight True\n",
      "transformer.h.13.mlp.c_fc.bias True\n",
      "transformer.h.13.mlp.c_proj.weight True\n",
      "transformer.h.13.mlp.c_proj.bias True\n",
      "transformer.h.14.ln_1.weight True\n",
      "transformer.h.14.ln_1.bias True\n",
      "transformer.h.14.attn.attention.k_proj.weight True\n",
      "transformer.h.14.attn.attention.v_proj.weight True\n",
      "transformer.h.14.attn.attention.q_proj.weight True\n",
      "transformer.h.14.attn.attention.out_proj.weight True\n",
      "transformer.h.14.attn.attention.out_proj.bias True\n",
      "transformer.h.14.ln_2.weight True\n",
      "transformer.h.14.ln_2.bias True\n",
      "transformer.h.14.mlp.c_fc.weight True\n",
      "transformer.h.14.mlp.c_fc.bias True\n",
      "transformer.h.14.mlp.c_proj.weight True\n",
      "transformer.h.14.mlp.c_proj.bias True\n",
      "transformer.h.15.ln_1.weight True\n",
      "transformer.h.15.ln_1.bias True\n",
      "transformer.h.15.attn.attention.k_proj.weight True\n",
      "transformer.h.15.attn.attention.v_proj.weight True\n",
      "transformer.h.15.attn.attention.q_proj.weight True\n",
      "transformer.h.15.attn.attention.out_proj.weight True\n",
      "transformer.h.15.attn.attention.out_proj.bias True\n",
      "transformer.h.15.ln_2.weight True\n",
      "transformer.h.15.ln_2.bias True\n",
      "transformer.h.15.mlp.c_fc.weight True\n",
      "transformer.h.15.mlp.c_fc.bias True\n",
      "transformer.h.15.mlp.c_proj.weight True\n",
      "transformer.h.15.mlp.c_proj.bias True\n",
      "transformer.h.16.ln_1.weight True\n",
      "transformer.h.16.ln_1.bias True\n",
      "transformer.h.16.attn.attention.k_proj.weight True\n",
      "transformer.h.16.attn.attention.v_proj.weight True\n",
      "transformer.h.16.attn.attention.q_proj.weight True\n",
      "transformer.h.16.attn.attention.out_proj.weight True\n",
      "transformer.h.16.attn.attention.out_proj.bias True\n",
      "transformer.h.16.ln_2.weight True\n",
      "transformer.h.16.ln_2.bias True\n",
      "transformer.h.16.mlp.c_fc.weight True\n",
      "transformer.h.16.mlp.c_fc.bias True\n",
      "transformer.h.16.mlp.c_proj.weight True\n",
      "transformer.h.16.mlp.c_proj.bias True\n",
      "transformer.h.17.ln_1.weight True\n",
      "transformer.h.17.ln_1.bias True\n",
      "transformer.h.17.attn.attention.k_proj.weight True\n",
      "transformer.h.17.attn.attention.v_proj.weight True\n",
      "transformer.h.17.attn.attention.q_proj.weight True\n",
      "transformer.h.17.attn.attention.out_proj.weight True\n",
      "transformer.h.17.attn.attention.out_proj.bias True\n",
      "transformer.h.17.ln_2.weight True\n",
      "transformer.h.17.ln_2.bias True\n",
      "transformer.h.17.mlp.c_fc.weight True\n",
      "transformer.h.17.mlp.c_fc.bias True\n",
      "transformer.h.17.mlp.c_proj.weight True\n",
      "transformer.h.17.mlp.c_proj.bias True\n",
      "transformer.h.18.ln_1.weight True\n",
      "transformer.h.18.ln_1.bias True\n",
      "transformer.h.18.attn.attention.k_proj.weight True\n",
      "transformer.h.18.attn.attention.v_proj.weight True\n",
      "transformer.h.18.attn.attention.q_proj.weight True\n",
      "transformer.h.18.attn.attention.out_proj.weight True\n",
      "transformer.h.18.attn.attention.out_proj.bias True\n",
      "transformer.h.18.ln_2.weight True\n",
      "transformer.h.18.ln_2.bias True\n",
      "transformer.h.18.mlp.c_fc.weight True\n",
      "transformer.h.18.mlp.c_fc.bias True\n",
      "transformer.h.18.mlp.c_proj.weight True\n",
      "transformer.h.18.mlp.c_proj.bias True\n",
      "transformer.h.19.ln_1.weight True\n",
      "transformer.h.19.ln_1.bias True\n",
      "transformer.h.19.attn.attention.k_proj.weight True\n",
      "transformer.h.19.attn.attention.v_proj.weight True\n",
      "transformer.h.19.attn.attention.q_proj.weight True\n",
      "transformer.h.19.attn.attention.out_proj.weight True\n",
      "transformer.h.19.attn.attention.out_proj.bias True\n",
      "transformer.h.19.ln_2.weight True\n",
      "transformer.h.19.ln_2.bias True\n",
      "transformer.h.19.mlp.c_fc.weight True\n",
      "transformer.h.19.mlp.c_fc.bias True\n",
      "transformer.h.19.mlp.c_proj.weight True\n",
      "transformer.h.19.mlp.c_proj.bias True\n",
      "transformer.h.20.ln_1.weight True\n",
      "transformer.h.20.ln_1.bias True\n",
      "transformer.h.20.attn.attention.k_proj.weight True\n",
      "transformer.h.20.attn.attention.v_proj.weight True\n",
      "transformer.h.20.attn.attention.q_proj.weight True\n",
      "transformer.h.20.attn.attention.out_proj.weight True\n",
      "transformer.h.20.attn.attention.out_proj.bias True\n",
      "transformer.h.20.ln_2.weight True\n",
      "transformer.h.20.ln_2.bias True\n",
      "transformer.h.20.mlp.c_fc.weight True\n",
      "transformer.h.20.mlp.c_fc.bias True\n",
      "transformer.h.20.mlp.c_proj.weight True\n",
      "transformer.h.20.mlp.c_proj.bias True\n",
      "transformer.h.21.ln_1.weight True\n",
      "transformer.h.21.ln_1.bias True\n",
      "transformer.h.21.attn.attention.k_proj.weight True\n",
      "transformer.h.21.attn.attention.v_proj.weight True\n",
      "transformer.h.21.attn.attention.q_proj.weight True\n",
      "transformer.h.21.attn.attention.out_proj.weight True\n",
      "transformer.h.21.attn.attention.out_proj.bias True\n",
      "transformer.h.21.ln_2.weight True\n",
      "transformer.h.21.ln_2.bias True\n",
      "transformer.h.21.mlp.c_fc.weight True\n",
      "transformer.h.21.mlp.c_fc.bias True\n",
      "transformer.h.21.mlp.c_proj.weight True\n",
      "transformer.h.21.mlp.c_proj.bias True\n",
      "transformer.h.22.ln_1.weight True\n",
      "transformer.h.22.ln_1.bias True\n",
      "transformer.h.22.attn.attention.k_proj.weight True\n",
      "transformer.h.22.attn.attention.v_proj.weight True\n",
      "transformer.h.22.attn.attention.q_proj.weight True\n",
      "transformer.h.22.attn.attention.out_proj.weight True\n",
      "transformer.h.22.attn.attention.out_proj.bias True\n",
      "transformer.h.22.ln_2.weight True\n",
      "transformer.h.22.ln_2.bias True\n",
      "transformer.h.22.mlp.c_fc.weight True\n",
      "transformer.h.22.mlp.c_fc.bias True\n",
      "transformer.h.22.mlp.c_proj.weight True\n",
      "transformer.h.22.mlp.c_proj.bias True\n",
      "transformer.h.23.ln_1.weight True\n",
      "transformer.h.23.ln_1.bias True\n",
      "transformer.h.23.attn.attention.k_proj.weight True\n",
      "transformer.h.23.attn.attention.v_proj.weight True\n",
      "transformer.h.23.attn.attention.q_proj.weight True\n",
      "transformer.h.23.attn.attention.out_proj.weight True\n",
      "transformer.h.23.attn.attention.out_proj.bias True\n",
      "transformer.h.23.ln_2.weight True\n",
      "transformer.h.23.ln_2.bias True\n",
      "transformer.h.23.mlp.c_fc.weight True\n",
      "transformer.h.23.mlp.c_fc.bias True\n",
      "transformer.h.23.mlp.c_proj.weight True\n",
      "transformer.h.23.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_neo.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the first two layers and 23 hidden units\n",
    "for name, param in model_neo.named_parameters():\n",
    "    if name.startswith(\"transformer.wte\"):\n",
    "        param.requires_grad = False\n",
    "    if name.startswith(\"transformer.wpe\"):\n",
    "        param.requires_grad = False\n",
    "    if any(x in name for x in ['.' + str(x) + '.' for x in range(23)]):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight False\n",
      "transformer.wpe.weight False\n",
      "transformer.h.0.ln_1.weight False\n",
      "transformer.h.0.ln_1.bias False\n",
      "transformer.h.0.attn.attention.k_proj.weight False\n",
      "transformer.h.0.attn.attention.v_proj.weight False\n",
      "transformer.h.0.attn.attention.q_proj.weight False\n",
      "transformer.h.0.attn.attention.out_proj.weight False\n",
      "transformer.h.0.attn.attention.out_proj.bias False\n",
      "transformer.h.0.ln_2.weight False\n",
      "transformer.h.0.ln_2.bias False\n",
      "transformer.h.0.mlp.c_fc.weight False\n",
      "transformer.h.0.mlp.c_fc.bias False\n",
      "transformer.h.0.mlp.c_proj.weight False\n",
      "transformer.h.0.mlp.c_proj.bias False\n",
      "transformer.h.1.ln_1.weight False\n",
      "transformer.h.1.ln_1.bias False\n",
      "transformer.h.1.attn.attention.k_proj.weight False\n",
      "transformer.h.1.attn.attention.v_proj.weight False\n",
      "transformer.h.1.attn.attention.q_proj.weight False\n",
      "transformer.h.1.attn.attention.out_proj.weight False\n",
      "transformer.h.1.attn.attention.out_proj.bias False\n",
      "transformer.h.1.ln_2.weight False\n",
      "transformer.h.1.ln_2.bias False\n",
      "transformer.h.1.mlp.c_fc.weight False\n",
      "transformer.h.1.mlp.c_fc.bias False\n",
      "transformer.h.1.mlp.c_proj.weight False\n",
      "transformer.h.1.mlp.c_proj.bias False\n",
      "transformer.h.2.ln_1.weight False\n",
      "transformer.h.2.ln_1.bias False\n",
      "transformer.h.2.attn.attention.k_proj.weight False\n",
      "transformer.h.2.attn.attention.v_proj.weight False\n",
      "transformer.h.2.attn.attention.q_proj.weight False\n",
      "transformer.h.2.attn.attention.out_proj.weight False\n",
      "transformer.h.2.attn.attention.out_proj.bias False\n",
      "transformer.h.2.ln_2.weight False\n",
      "transformer.h.2.ln_2.bias False\n",
      "transformer.h.2.mlp.c_fc.weight False\n",
      "transformer.h.2.mlp.c_fc.bias False\n",
      "transformer.h.2.mlp.c_proj.weight False\n",
      "transformer.h.2.mlp.c_proj.bias False\n",
      "transformer.h.3.ln_1.weight False\n",
      "transformer.h.3.ln_1.bias False\n",
      "transformer.h.3.attn.attention.k_proj.weight False\n",
      "transformer.h.3.attn.attention.v_proj.weight False\n",
      "transformer.h.3.attn.attention.q_proj.weight False\n",
      "transformer.h.3.attn.attention.out_proj.weight False\n",
      "transformer.h.3.attn.attention.out_proj.bias False\n",
      "transformer.h.3.ln_2.weight False\n",
      "transformer.h.3.ln_2.bias False\n",
      "transformer.h.3.mlp.c_fc.weight False\n",
      "transformer.h.3.mlp.c_fc.bias False\n",
      "transformer.h.3.mlp.c_proj.weight False\n",
      "transformer.h.3.mlp.c_proj.bias False\n",
      "transformer.h.4.ln_1.weight False\n",
      "transformer.h.4.ln_1.bias False\n",
      "transformer.h.4.attn.attention.k_proj.weight False\n",
      "transformer.h.4.attn.attention.v_proj.weight False\n",
      "transformer.h.4.attn.attention.q_proj.weight False\n",
      "transformer.h.4.attn.attention.out_proj.weight False\n",
      "transformer.h.4.attn.attention.out_proj.bias False\n",
      "transformer.h.4.ln_2.weight False\n",
      "transformer.h.4.ln_2.bias False\n",
      "transformer.h.4.mlp.c_fc.weight False\n",
      "transformer.h.4.mlp.c_fc.bias False\n",
      "transformer.h.4.mlp.c_proj.weight False\n",
      "transformer.h.4.mlp.c_proj.bias False\n",
      "transformer.h.5.ln_1.weight False\n",
      "transformer.h.5.ln_1.bias False\n",
      "transformer.h.5.attn.attention.k_proj.weight False\n",
      "transformer.h.5.attn.attention.v_proj.weight False\n",
      "transformer.h.5.attn.attention.q_proj.weight False\n",
      "transformer.h.5.attn.attention.out_proj.weight False\n",
      "transformer.h.5.attn.attention.out_proj.bias False\n",
      "transformer.h.5.ln_2.weight False\n",
      "transformer.h.5.ln_2.bias False\n",
      "transformer.h.5.mlp.c_fc.weight False\n",
      "transformer.h.5.mlp.c_fc.bias False\n",
      "transformer.h.5.mlp.c_proj.weight False\n",
      "transformer.h.5.mlp.c_proj.bias False\n",
      "transformer.h.6.ln_1.weight False\n",
      "transformer.h.6.ln_1.bias False\n",
      "transformer.h.6.attn.attention.k_proj.weight False\n",
      "transformer.h.6.attn.attention.v_proj.weight False\n",
      "transformer.h.6.attn.attention.q_proj.weight False\n",
      "transformer.h.6.attn.attention.out_proj.weight False\n",
      "transformer.h.6.attn.attention.out_proj.bias False\n",
      "transformer.h.6.ln_2.weight False\n",
      "transformer.h.6.ln_2.bias False\n",
      "transformer.h.6.mlp.c_fc.weight False\n",
      "transformer.h.6.mlp.c_fc.bias False\n",
      "transformer.h.6.mlp.c_proj.weight False\n",
      "transformer.h.6.mlp.c_proj.bias False\n",
      "transformer.h.7.ln_1.weight False\n",
      "transformer.h.7.ln_1.bias False\n",
      "transformer.h.7.attn.attention.k_proj.weight False\n",
      "transformer.h.7.attn.attention.v_proj.weight False\n",
      "transformer.h.7.attn.attention.q_proj.weight False\n",
      "transformer.h.7.attn.attention.out_proj.weight False\n",
      "transformer.h.7.attn.attention.out_proj.bias False\n",
      "transformer.h.7.ln_2.weight False\n",
      "transformer.h.7.ln_2.bias False\n",
      "transformer.h.7.mlp.c_fc.weight False\n",
      "transformer.h.7.mlp.c_fc.bias False\n",
      "transformer.h.7.mlp.c_proj.weight False\n",
      "transformer.h.7.mlp.c_proj.bias False\n",
      "transformer.h.8.ln_1.weight False\n",
      "transformer.h.8.ln_1.bias False\n",
      "transformer.h.8.attn.attention.k_proj.weight False\n",
      "transformer.h.8.attn.attention.v_proj.weight False\n",
      "transformer.h.8.attn.attention.q_proj.weight False\n",
      "transformer.h.8.attn.attention.out_proj.weight False\n",
      "transformer.h.8.attn.attention.out_proj.bias False\n",
      "transformer.h.8.ln_2.weight False\n",
      "transformer.h.8.ln_2.bias False\n",
      "transformer.h.8.mlp.c_fc.weight False\n",
      "transformer.h.8.mlp.c_fc.bias False\n",
      "transformer.h.8.mlp.c_proj.weight False\n",
      "transformer.h.8.mlp.c_proj.bias False\n",
      "transformer.h.9.ln_1.weight False\n",
      "transformer.h.9.ln_1.bias False\n",
      "transformer.h.9.attn.attention.k_proj.weight False\n",
      "transformer.h.9.attn.attention.v_proj.weight False\n",
      "transformer.h.9.attn.attention.q_proj.weight False\n",
      "transformer.h.9.attn.attention.out_proj.weight False\n",
      "transformer.h.9.attn.attention.out_proj.bias False\n",
      "transformer.h.9.ln_2.weight False\n",
      "transformer.h.9.ln_2.bias False\n",
      "transformer.h.9.mlp.c_fc.weight False\n",
      "transformer.h.9.mlp.c_fc.bias False\n",
      "transformer.h.9.mlp.c_proj.weight False\n",
      "transformer.h.9.mlp.c_proj.bias False\n",
      "transformer.h.10.ln_1.weight False\n",
      "transformer.h.10.ln_1.bias False\n",
      "transformer.h.10.attn.attention.k_proj.weight False\n",
      "transformer.h.10.attn.attention.v_proj.weight False\n",
      "transformer.h.10.attn.attention.q_proj.weight False\n",
      "transformer.h.10.attn.attention.out_proj.weight False\n",
      "transformer.h.10.attn.attention.out_proj.bias False\n",
      "transformer.h.10.ln_2.weight False\n",
      "transformer.h.10.ln_2.bias False\n",
      "transformer.h.10.mlp.c_fc.weight False\n",
      "transformer.h.10.mlp.c_fc.bias False\n",
      "transformer.h.10.mlp.c_proj.weight False\n",
      "transformer.h.10.mlp.c_proj.bias False\n",
      "transformer.h.11.ln_1.weight False\n",
      "transformer.h.11.ln_1.bias False\n",
      "transformer.h.11.attn.attention.k_proj.weight False\n",
      "transformer.h.11.attn.attention.v_proj.weight False\n",
      "transformer.h.11.attn.attention.q_proj.weight False\n",
      "transformer.h.11.attn.attention.out_proj.weight False\n",
      "transformer.h.11.attn.attention.out_proj.bias False\n",
      "transformer.h.11.ln_2.weight False\n",
      "transformer.h.11.ln_2.bias False\n",
      "transformer.h.11.mlp.c_fc.weight False\n",
      "transformer.h.11.mlp.c_fc.bias False\n",
      "transformer.h.11.mlp.c_proj.weight False\n",
      "transformer.h.11.mlp.c_proj.bias False\n",
      "transformer.h.12.ln_1.weight False\n",
      "transformer.h.12.ln_1.bias False\n",
      "transformer.h.12.attn.attention.k_proj.weight False\n",
      "transformer.h.12.attn.attention.v_proj.weight False\n",
      "transformer.h.12.attn.attention.q_proj.weight False\n",
      "transformer.h.12.attn.attention.out_proj.weight False\n",
      "transformer.h.12.attn.attention.out_proj.bias False\n",
      "transformer.h.12.ln_2.weight False\n",
      "transformer.h.12.ln_2.bias False\n",
      "transformer.h.12.mlp.c_fc.weight False\n",
      "transformer.h.12.mlp.c_fc.bias False\n",
      "transformer.h.12.mlp.c_proj.weight False\n",
      "transformer.h.12.mlp.c_proj.bias False\n",
      "transformer.h.13.ln_1.weight False\n",
      "transformer.h.13.ln_1.bias False\n",
      "transformer.h.13.attn.attention.k_proj.weight False\n",
      "transformer.h.13.attn.attention.v_proj.weight False\n",
      "transformer.h.13.attn.attention.q_proj.weight False\n",
      "transformer.h.13.attn.attention.out_proj.weight False\n",
      "transformer.h.13.attn.attention.out_proj.bias False\n",
      "transformer.h.13.ln_2.weight False\n",
      "transformer.h.13.ln_2.bias False\n",
      "transformer.h.13.mlp.c_fc.weight False\n",
      "transformer.h.13.mlp.c_fc.bias False\n",
      "transformer.h.13.mlp.c_proj.weight False\n",
      "transformer.h.13.mlp.c_proj.bias False\n",
      "transformer.h.14.ln_1.weight False\n",
      "transformer.h.14.ln_1.bias False\n",
      "transformer.h.14.attn.attention.k_proj.weight False\n",
      "transformer.h.14.attn.attention.v_proj.weight False\n",
      "transformer.h.14.attn.attention.q_proj.weight False\n",
      "transformer.h.14.attn.attention.out_proj.weight False\n",
      "transformer.h.14.attn.attention.out_proj.bias False\n",
      "transformer.h.14.ln_2.weight False\n",
      "transformer.h.14.ln_2.bias False\n",
      "transformer.h.14.mlp.c_fc.weight False\n",
      "transformer.h.14.mlp.c_fc.bias False\n",
      "transformer.h.14.mlp.c_proj.weight False\n",
      "transformer.h.14.mlp.c_proj.bias False\n",
      "transformer.h.15.ln_1.weight False\n",
      "transformer.h.15.ln_1.bias False\n",
      "transformer.h.15.attn.attention.k_proj.weight False\n",
      "transformer.h.15.attn.attention.v_proj.weight False\n",
      "transformer.h.15.attn.attention.q_proj.weight False\n",
      "transformer.h.15.attn.attention.out_proj.weight False\n",
      "transformer.h.15.attn.attention.out_proj.bias False\n",
      "transformer.h.15.ln_2.weight False\n",
      "transformer.h.15.ln_2.bias False\n",
      "transformer.h.15.mlp.c_fc.weight False\n",
      "transformer.h.15.mlp.c_fc.bias False\n",
      "transformer.h.15.mlp.c_proj.weight False\n",
      "transformer.h.15.mlp.c_proj.bias False\n",
      "transformer.h.16.ln_1.weight False\n",
      "transformer.h.16.ln_1.bias False\n",
      "transformer.h.16.attn.attention.k_proj.weight False\n",
      "transformer.h.16.attn.attention.v_proj.weight False\n",
      "transformer.h.16.attn.attention.q_proj.weight False\n",
      "transformer.h.16.attn.attention.out_proj.weight False\n",
      "transformer.h.16.attn.attention.out_proj.bias False\n",
      "transformer.h.16.ln_2.weight False\n",
      "transformer.h.16.ln_2.bias False\n",
      "transformer.h.16.mlp.c_fc.weight False\n",
      "transformer.h.16.mlp.c_fc.bias False\n",
      "transformer.h.16.mlp.c_proj.weight False\n",
      "transformer.h.16.mlp.c_proj.bias False\n",
      "transformer.h.17.ln_1.weight False\n",
      "transformer.h.17.ln_1.bias False\n",
      "transformer.h.17.attn.attention.k_proj.weight False\n",
      "transformer.h.17.attn.attention.v_proj.weight False\n",
      "transformer.h.17.attn.attention.q_proj.weight False\n",
      "transformer.h.17.attn.attention.out_proj.weight False\n",
      "transformer.h.17.attn.attention.out_proj.bias False\n",
      "transformer.h.17.ln_2.weight False\n",
      "transformer.h.17.ln_2.bias False\n",
      "transformer.h.17.mlp.c_fc.weight False\n",
      "transformer.h.17.mlp.c_fc.bias False\n",
      "transformer.h.17.mlp.c_proj.weight False\n",
      "transformer.h.17.mlp.c_proj.bias False\n",
      "transformer.h.18.ln_1.weight False\n",
      "transformer.h.18.ln_1.bias False\n",
      "transformer.h.18.attn.attention.k_proj.weight False\n",
      "transformer.h.18.attn.attention.v_proj.weight False\n",
      "transformer.h.18.attn.attention.q_proj.weight False\n",
      "transformer.h.18.attn.attention.out_proj.weight False\n",
      "transformer.h.18.attn.attention.out_proj.bias False\n",
      "transformer.h.18.ln_2.weight False\n",
      "transformer.h.18.ln_2.bias False\n",
      "transformer.h.18.mlp.c_fc.weight False\n",
      "transformer.h.18.mlp.c_fc.bias False\n",
      "transformer.h.18.mlp.c_proj.weight False\n",
      "transformer.h.18.mlp.c_proj.bias False\n",
      "transformer.h.19.ln_1.weight False\n",
      "transformer.h.19.ln_1.bias False\n",
      "transformer.h.19.attn.attention.k_proj.weight False\n",
      "transformer.h.19.attn.attention.v_proj.weight False\n",
      "transformer.h.19.attn.attention.q_proj.weight False\n",
      "transformer.h.19.attn.attention.out_proj.weight False\n",
      "transformer.h.19.attn.attention.out_proj.bias False\n",
      "transformer.h.19.ln_2.weight False\n",
      "transformer.h.19.ln_2.bias False\n",
      "transformer.h.19.mlp.c_fc.weight False\n",
      "transformer.h.19.mlp.c_fc.bias False\n",
      "transformer.h.19.mlp.c_proj.weight False\n",
      "transformer.h.19.mlp.c_proj.bias False\n",
      "transformer.h.20.ln_1.weight False\n",
      "transformer.h.20.ln_1.bias False\n",
      "transformer.h.20.attn.attention.k_proj.weight False\n",
      "transformer.h.20.attn.attention.v_proj.weight False\n",
      "transformer.h.20.attn.attention.q_proj.weight False\n",
      "transformer.h.20.attn.attention.out_proj.weight False\n",
      "transformer.h.20.attn.attention.out_proj.bias False\n",
      "transformer.h.20.ln_2.weight False\n",
      "transformer.h.20.ln_2.bias False\n",
      "transformer.h.20.mlp.c_fc.weight False\n",
      "transformer.h.20.mlp.c_fc.bias False\n",
      "transformer.h.20.mlp.c_proj.weight False\n",
      "transformer.h.20.mlp.c_proj.bias False\n",
      "transformer.h.21.ln_1.weight False\n",
      "transformer.h.21.ln_1.bias False\n",
      "transformer.h.21.attn.attention.k_proj.weight False\n",
      "transformer.h.21.attn.attention.v_proj.weight False\n",
      "transformer.h.21.attn.attention.q_proj.weight False\n",
      "transformer.h.21.attn.attention.out_proj.weight False\n",
      "transformer.h.21.attn.attention.out_proj.bias False\n",
      "transformer.h.21.ln_2.weight False\n",
      "transformer.h.21.ln_2.bias False\n",
      "transformer.h.21.mlp.c_fc.weight False\n",
      "transformer.h.21.mlp.c_fc.bias False\n",
      "transformer.h.21.mlp.c_proj.weight False\n",
      "transformer.h.21.mlp.c_proj.bias False\n",
      "transformer.h.22.ln_1.weight False\n",
      "transformer.h.22.ln_1.bias False\n",
      "transformer.h.22.attn.attention.k_proj.weight False\n",
      "transformer.h.22.attn.attention.v_proj.weight False\n",
      "transformer.h.22.attn.attention.q_proj.weight False\n",
      "transformer.h.22.attn.attention.out_proj.weight False\n",
      "transformer.h.22.attn.attention.out_proj.bias False\n",
      "transformer.h.22.ln_2.weight False\n",
      "transformer.h.22.ln_2.bias False\n",
      "transformer.h.22.mlp.c_fc.weight False\n",
      "transformer.h.22.mlp.c_fc.bias False\n",
      "transformer.h.22.mlp.c_proj.weight False\n",
      "transformer.h.22.mlp.c_proj.bias False\n",
      "transformer.h.23.ln_1.weight True\n",
      "transformer.h.23.ln_1.bias True\n",
      "transformer.h.23.attn.attention.k_proj.weight True\n",
      "transformer.h.23.attn.attention.v_proj.weight True\n",
      "transformer.h.23.attn.attention.q_proj.weight True\n",
      "transformer.h.23.attn.attention.out_proj.weight True\n",
      "transformer.h.23.attn.attention.out_proj.bias True\n",
      "transformer.h.23.ln_2.weight True\n",
      "transformer.h.23.ln_2.bias True\n",
      "transformer.h.23.mlp.c_fc.weight True\n",
      "transformer.h.23.mlp.c_fc.bias True\n",
      "transformer.h.23.mlp.c_proj.weight True\n",
      "transformer.h.23.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "# check layers\n",
    "for name, param in model_neo.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shayne Kaiser\\anaconda3\\envs\\poetryproject\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2776605\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 277661\n",
      "  Number of trainable parameters = 50356224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa88b8d6f7e84973ac677e7a59b0d559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8757, 'learning_rate': 4.8200978926782185e-05, 'epoch': 0.04}\n",
      "{'loss': 0.8238, 'learning_rate': 4.640015703166925e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8112, 'learning_rate': 4.459933513655633e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8019, 'learning_rate': 4.27985132414434e-05, 'epoch': 0.14}\n",
      "{'loss': 0.7945, 'learning_rate': 4.099769134633047e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7902, 'learning_rate': 3.919686945121754e-05, 'epoch': 0.22}\n",
      "{'loss': 0.7844, 'learning_rate': 3.739604755610461e-05, 'epoch': 0.25}\n",
      "{'loss': 0.7811, 'learning_rate': 3.559522566099168e-05, 'epoch': 0.29}\n",
      "{'loss': 0.7778, 'learning_rate': 3.3794403765878745e-05, 'epoch': 0.32}\n",
      "{'loss': 0.7751, 'learning_rate': 3.199358187076582e-05, 'epoch': 0.36}\n",
      "{'loss': 0.7725, 'learning_rate': 3.019275997565289e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7696, 'learning_rate': 2.839193808053996e-05, 'epoch': 0.43}\n",
      "{'loss': 0.7676, 'learning_rate': 2.659111618542703e-05, 'epoch': 0.47}\n",
      "{'loss': 0.7668, 'learning_rate': 2.47902942903141e-05, 'epoch': 0.5}\n",
      "{'loss': 0.7636, 'learning_rate': 2.298947239520117e-05, 'epoch': 0.54}\n",
      "{'loss': 0.7623, 'learning_rate': 2.118865050008824e-05, 'epoch': 0.58}\n",
      "{'loss': 0.7599, 'learning_rate': 1.938782860497531e-05, 'epoch': 0.61}\n",
      "{'loss': 0.7588, 'learning_rate': 1.7587006709862385e-05, 'epoch': 0.65}\n",
      "{'loss': 0.758, 'learning_rate': 1.5786184814749453e-05, 'epoch': 0.68}\n",
      "{'loss': 0.7573, 'learning_rate': 1.3985362919636521e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7553, 'learning_rate': 1.2184541024523593e-05, 'epoch': 0.76}\n",
      "{'loss': 0.7539, 'learning_rate': 1.0383719129410665e-05, 'epoch': 0.79}\n",
      "{'loss': 0.7536, 'learning_rate': 8.582897234297733e-06, 'epoch': 0.83}\n",
      "{'loss': 0.7511, 'learning_rate': 6.782075339184804e-06, 'epoch': 0.86}\n",
      "{'loss': 0.752, 'learning_rate': 4.981253444071874e-06, 'epoch': 0.9}\n",
      "{'loss': 0.7505, 'learning_rate': 3.1804315489589452e-06, 'epoch': 0.94}\n",
      "{'loss': 0.7505, 'learning_rate': 1.3796096538460155e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 123748.8893, 'train_samples_per_second': 22.437, 'train_steps_per_second': 2.244, 'train_loss': 0.7741056002052638, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=277661, training_loss=0.7741056002052638, metrics={'train_runtime': 123748.8893, 'train_samples_per_second': 22.437, 'train_steps_per_second': 2.244, 'train_loss': 0.7741056002052638, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainer(model=model_neo,  args=training_args_neo, train_dataset=train_dataset_neo, \n",
    "        eval_dataset=val_dataset_neo, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0] for f in data])}).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/GPT-Neo\\config.json\n",
      "Model weights saved in ./Models/GPT-Neo\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save model and Tokenizer\n",
    "model_neo.save_pretrained(\"./Models/GPT-Neo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./Models/GPT-Neo\\tokenizer_config.json\n",
      "Special tokens file saved in ./Models/GPT-Neo\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Models/GPT-Neo\\\\tokenizer_config.json',\n",
       " './Models/GPT-Neo\\\\special_tokens_map.json',\n",
       " './Models/GPT-Neo\\\\vocab.json',\n",
       " './Models/GPT-Neo\\\\merges.txt',\n",
       " './Models/GPT-Neo\\\\added_tokens.json',\n",
       " './Models/GPT-Neo\\\\tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_neo.save_pretrained(\"./Models/GPT-Neo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in saved model and tokenizer \n",
    "tokenizer_neo = AutoTokenizer.from_pretrained(\"./Models/GPT-Neo\")\n",
    "model_neo = AutoModelForCausalLM.from_pretrained(\"./Models/GPT-Neo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: In view of the fading animals\n",
      "0:  In view of the fading animals from every He hestarkainers oned as I\n",
      "1:  In view of the fading animals of\n",
      "2:  In view of the fading animals,\n",
      "3:  In view of the fading animals of\n",
      "4:  In view of the fading animals his mind, by the\n",
      "5:  In view of the fading animals,\n",
      "6:  In view of the fading animals;\n",
      "7:  In view of the fading animals on us with no eye,\n",
      "8:  In view of the fading animals,\n",
      "9:  In view of the fading animals's Now\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model_neo, tokenizer_neo, \"In view of the fading animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Shall I compare thee\n",
      "0:  Shall I compare thee, my Godhead with thee;\n",
      "1:  Shall I compare thee with his life\n",
      "2:  Shall I compare thee now.\n",
      "3:  Shall I compare thee with him, which he\n",
      "4:  Shall I compare thee?--the son of Men.\n",
      "5:  Shall I compare thee? Shall it give thy face\n",
      "6:  Shall I compare thee: a son born of a lord\n",
      "7:  Shall I compare thee with him alone, then in peace thou hast hast?\n",
      "8:  Shall I compare thee to the king's wrath?\n",
      "9:  Shall I compare thee unto us:--_It be;\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"Shall I compare thee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness\n",
      "0:  Deep into that darkness that never sees--and knows--.\"\n",
      "1:  Deep into that darkness.\"  He paused then:\n",
      "2:  Deep into that darkness, with the sea waves,\n",
      "3:  Deep into that darkness, and his blood a mist in her,\n",
      "4:  Deep into that darkness the darkness. I stand;\n",
      "5:  Deep into that darkness in that sky?...\n",
      "6:  Deep into that darkness\n",
      "7:  Deep into that darkness,--who at this moment\n",
      "8:  Deep into that darkness; and this life\n",
      "9:  Deep into that darkness\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"Deep into that darkness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "0:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "1:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I.\n",
      "2:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "3:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "4:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "5:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "6:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "7:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "8:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "9:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I,\n"
     ]
    }
   ],
   "source": [
    "long_prompt = 'Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I'\n",
    "\n",
    "generate_from_model(model, tokenizer, long_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Finished\n",
      "0:  Finished to-day, but thy word the the\n",
      "1:  Finisheds, whose fings'er not was the seare of gold,\n",
      "2:  Finished of each country is\n",
      "3:  Finished; was of thy's y at that I say--\n",
      "4:  Finished, but and his own with a dream of her, \" was said, I went.\" it is done.--_\n",
      "5:  Finished thou for dainei, is no\n",
      "6:  Finished, and so had no gild-man to me.\n",
      "7:  Finished I'd on the world which in a bl the st\n",
      "8:  Finished that is a while that wrees\n",
      "9:  Finished in in his eyes from the morning to know of  He I have I say--\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model_neo, tokenizer_neo, \"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Finished\n",
      "0:  Finished from me the way the others are;--\n",
      "1:  Finished them round and stood with ease to walk\n",
      "2:  Finished thy song--this my Lord\n",
      "3:  Finished, and his hair is all pink as with hair;\n",
      "4:  Finished, and for a while his tongue so loud had\n",
      "5:  Finished one little day and the night became;\n",
      "6:  Finished and bound at the head\n",
      "7:  Finished up, like the sea aflame. But never left a trace\n",
      "8:  Finished: about four pounds,\n",
      "9:  Finished the journey, or in vain, with his eye\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('poetryproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed33b6c83ed5036cd92c69b03bba619a7b3d4b7bbbfa1b7f16f401f486e9f1b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
