{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration cakiki--gutenberg-poetry-corpus-7745b6aecdad34dc\n",
      "Found cached dataset parquet (C:/Users/Shayne Kaiser/.cache/huggingface/datasets/biglam___parquet/cakiki--gutenberg-poetry-corpus-7745b6aecdad34dc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = load_dataset(\"biglam/gutenberg-poetry-corpus\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['line', 'gutenberg_id'],\n",
       "    num_rows: 3085117\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to Pandas\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (3085117, 2)\n"
     ]
    }
   ],
   "source": [
    "print('df shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Song of Hiawatha is based on the legends a...\n",
       "1    many North American Indian tribes, but especia...\n",
       "2    Ojibway Indians of northern Michigan, Wisconsi...\n",
       "3    They were collected by Henry Rowe Schoolcraft,...\n",
       "4    Schoolcraft married Jane, O-bah-bahm-wawa-ge-z...\n",
       "Name: line, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = df[\"line\"]\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryDataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length):\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "        for txt in txt_list:\n",
    "            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation=True,\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating text \n",
    "def generate_from_model(model, tokenizer, prompt, max_length=300, temp=1.5, num_outputs=10):\n",
    "    \"\"\"\n",
    "    Tokenize the given prompt, must be one string, and generate output from a  provided model and tokenizer.\n",
    "\n",
    "    Args:\n",
    "        mondel (transformers.model): The model being used to generate text\n",
    "        tokenizer: the tokenizer being used\n",
    "        prompt (str): The input string that is used to generate text\n",
    "        max_length (int): Max character length of the generated outputs\n",
    "        temp (int): Set the temperature for the outputs\n",
    "        num_outputs (int): number of different outputs to be created\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\"Outputs for: \" + prompt)\n",
    "\n",
    "    generated = tokenizer(\"<|startoftext|> \" + prompt, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    sample_outputs = model.generate(generated, max_length=max_length, do_sample=True, top_p=0.95, top_k=50, temperature=temp, num_return_sequences=num_outputs)\n",
    "\n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "        print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilGPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model\n",
    "torch.manual_seed(92)\n",
    "\n",
    "MODEL_NAME = \"distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./Models/DistilGPT2', num_train_epochs=1, logging_steps=10000, save_steps=50000,\n",
    "                                  per_device_train_batch_size=10, per_device_eval_batch_size=10, warmup_steps=10,\n",
    "                                   weight_decay=0.05, logging_dir='./Models/DistilGPT2/logs', report_to='none' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(tokenizer.encode(line)) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization_dataset = PoetryDataset(lines, tokenizer, max_length=max_length)\n",
    "train_size = int(0.9  * len(tokenization_dataset))\n",
    "train_dataset, val_dataset = random_split(tokenization_dataset, [train_size, len(tokenization_dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50257,   818,   262,  7032,   262,   302,   521, 28153,  4836,   606,\n",
       "         11496, 50256, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training dataset: 2776605\n",
      "Length of Validation dataset: 308512\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of Training dataset: {len(train_dataset)}\")\n",
    "print(f\"Length of Validation dataset: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight True\n",
      "transformer.wpe.weight True\n",
      "transformer.h.0.ln_1.weight True\n",
      "transformer.h.0.ln_1.bias True\n",
      "transformer.h.0.attn.c_attn.weight True\n",
      "transformer.h.0.attn.c_attn.bias True\n",
      "transformer.h.0.attn.c_proj.weight True\n",
      "transformer.h.0.attn.c_proj.bias True\n",
      "transformer.h.0.ln_2.weight True\n",
      "transformer.h.0.ln_2.bias True\n",
      "transformer.h.0.mlp.c_fc.weight True\n",
      "transformer.h.0.mlp.c_fc.bias True\n",
      "transformer.h.0.mlp.c_proj.weight True\n",
      "transformer.h.0.mlp.c_proj.bias True\n",
      "transformer.h.1.ln_1.weight True\n",
      "transformer.h.1.ln_1.bias True\n",
      "transformer.h.1.attn.c_attn.weight True\n",
      "transformer.h.1.attn.c_attn.bias True\n",
      "transformer.h.1.attn.c_proj.weight True\n",
      "transformer.h.1.attn.c_proj.bias True\n",
      "transformer.h.1.ln_2.weight True\n",
      "transformer.h.1.ln_2.bias True\n",
      "transformer.h.1.mlp.c_fc.weight True\n",
      "transformer.h.1.mlp.c_fc.bias True\n",
      "transformer.h.1.mlp.c_proj.weight True\n",
      "transformer.h.1.mlp.c_proj.bias True\n",
      "transformer.h.2.ln_1.weight True\n",
      "transformer.h.2.ln_1.bias True\n",
      "transformer.h.2.attn.c_attn.weight True\n",
      "transformer.h.2.attn.c_attn.bias True\n",
      "transformer.h.2.attn.c_proj.weight True\n",
      "transformer.h.2.attn.c_proj.bias True\n",
      "transformer.h.2.ln_2.weight True\n",
      "transformer.h.2.ln_2.bias True\n",
      "transformer.h.2.mlp.c_fc.weight True\n",
      "transformer.h.2.mlp.c_fc.bias True\n",
      "transformer.h.2.mlp.c_proj.weight True\n",
      "transformer.h.2.mlp.c_proj.bias True\n",
      "transformer.h.3.ln_1.weight True\n",
      "transformer.h.3.ln_1.bias True\n",
      "transformer.h.3.attn.c_attn.weight True\n",
      "transformer.h.3.attn.c_attn.bias True\n",
      "transformer.h.3.attn.c_proj.weight True\n",
      "transformer.h.3.attn.c_proj.bias True\n",
      "transformer.h.3.ln_2.weight True\n",
      "transformer.h.3.ln_2.bias True\n",
      "transformer.h.3.mlp.c_fc.weight True\n",
      "transformer.h.3.mlp.c_fc.bias True\n",
      "transformer.h.3.mlp.c_proj.weight True\n",
      "transformer.h.3.mlp.c_proj.bias True\n",
      "transformer.h.4.ln_1.weight True\n",
      "transformer.h.4.ln_1.bias True\n",
      "transformer.h.4.attn.c_attn.weight True\n",
      "transformer.h.4.attn.c_attn.bias True\n",
      "transformer.h.4.attn.c_proj.weight True\n",
      "transformer.h.4.attn.c_proj.bias True\n",
      "transformer.h.4.ln_2.weight True\n",
      "transformer.h.4.ln_2.bias True\n",
      "transformer.h.4.mlp.c_fc.weight True\n",
      "transformer.h.4.mlp.c_fc.bias True\n",
      "transformer.h.4.mlp.c_proj.weight True\n",
      "transformer.h.4.mlp.c_proj.bias True\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.c_attn.weight True\n",
      "transformer.h.5.attn.c_attn.bias True\n",
      "transformer.h.5.attn.c_proj.weight True\n",
      "transformer.h.5.attn.c_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "# check layers in the model\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the first two layers and 4 hidden units\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"transformer.wte\"):\n",
    "        param.requires_grad = False\n",
    "    if name.startswith(\"transformer.wpe\"):\n",
    "        param.requires_grad = False\n",
    "    if any(x in name for x in ['.' + str(x) + '.' for x in range(5)]):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight False\n",
      "transformer.wpe.weight False\n",
      "transformer.h.0.ln_1.weight False\n",
      "transformer.h.0.ln_1.bias False\n",
      "transformer.h.0.attn.c_attn.weight False\n",
      "transformer.h.0.attn.c_attn.bias False\n",
      "transformer.h.0.attn.c_proj.weight False\n",
      "transformer.h.0.attn.c_proj.bias False\n",
      "transformer.h.0.ln_2.weight False\n",
      "transformer.h.0.ln_2.bias False\n",
      "transformer.h.0.mlp.c_fc.weight False\n",
      "transformer.h.0.mlp.c_fc.bias False\n",
      "transformer.h.0.mlp.c_proj.weight False\n",
      "transformer.h.0.mlp.c_proj.bias False\n",
      "transformer.h.1.ln_1.weight False\n",
      "transformer.h.1.ln_1.bias False\n",
      "transformer.h.1.attn.c_attn.weight False\n",
      "transformer.h.1.attn.c_attn.bias False\n",
      "transformer.h.1.attn.c_proj.weight False\n",
      "transformer.h.1.attn.c_proj.bias False\n",
      "transformer.h.1.ln_2.weight False\n",
      "transformer.h.1.ln_2.bias False\n",
      "transformer.h.1.mlp.c_fc.weight False\n",
      "transformer.h.1.mlp.c_fc.bias False\n",
      "transformer.h.1.mlp.c_proj.weight False\n",
      "transformer.h.1.mlp.c_proj.bias False\n",
      "transformer.h.2.ln_1.weight False\n",
      "transformer.h.2.ln_1.bias False\n",
      "transformer.h.2.attn.c_attn.weight False\n",
      "transformer.h.2.attn.c_attn.bias False\n",
      "transformer.h.2.attn.c_proj.weight False\n",
      "transformer.h.2.attn.c_proj.bias False\n",
      "transformer.h.2.ln_2.weight False\n",
      "transformer.h.2.ln_2.bias False\n",
      "transformer.h.2.mlp.c_fc.weight False\n",
      "transformer.h.2.mlp.c_fc.bias False\n",
      "transformer.h.2.mlp.c_proj.weight False\n",
      "transformer.h.2.mlp.c_proj.bias False\n",
      "transformer.h.3.ln_1.weight False\n",
      "transformer.h.3.ln_1.bias False\n",
      "transformer.h.3.attn.c_attn.weight False\n",
      "transformer.h.3.attn.c_attn.bias False\n",
      "transformer.h.3.attn.c_proj.weight False\n",
      "transformer.h.3.attn.c_proj.bias False\n",
      "transformer.h.3.ln_2.weight False\n",
      "transformer.h.3.ln_2.bias False\n",
      "transformer.h.3.mlp.c_fc.weight False\n",
      "transformer.h.3.mlp.c_fc.bias False\n",
      "transformer.h.3.mlp.c_proj.weight False\n",
      "transformer.h.3.mlp.c_proj.bias False\n",
      "transformer.h.4.ln_1.weight False\n",
      "transformer.h.4.ln_1.bias False\n",
      "transformer.h.4.attn.c_attn.weight False\n",
      "transformer.h.4.attn.c_attn.bias False\n",
      "transformer.h.4.attn.c_proj.weight False\n",
      "transformer.h.4.attn.c_proj.bias False\n",
      "transformer.h.4.ln_2.weight False\n",
      "transformer.h.4.ln_2.bias False\n",
      "transformer.h.4.mlp.c_fc.weight False\n",
      "transformer.h.4.mlp.c_fc.bias False\n",
      "transformer.h.4.mlp.c_proj.weight False\n",
      "transformer.h.4.mlp.c_proj.bias False\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.c_attn.weight True\n",
      "transformer.h.5.attn.c_attn.bias True\n",
      "transformer.h.5.attn.c_proj.weight True\n",
      "transformer.h.5.attn.c_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "# now check layers\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shayne Kaiser\\anaconda3\\envs\\poetryproject\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2776605\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 277661\n",
      "  Number of trainable parameters = 7089408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c2548f192042ec9759ccb1fdc69b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7205, 'learning_rate': 4.8200978926782185e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6612, 'learning_rate': 4.640015703166925e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6561, 'learning_rate': 4.459933513655633e-05, 'epoch': 0.11}\n",
      "{'loss': 0.651, 'learning_rate': 4.27985132414434e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-50000\n",
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-50000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6485, 'learning_rate': 4.099769134633047e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-50000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6451, 'learning_rate': 3.919686945121754e-05, 'epoch': 0.22}\n",
      "{'loss': 0.6437, 'learning_rate': 3.739604755610461e-05, 'epoch': 0.25}\n",
      "{'loss': 0.6417, 'learning_rate': 3.559522566099168e-05, 'epoch': 0.29}\n",
      "{'loss': 0.6399, 'learning_rate': 3.3794403765878745e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6389, 'learning_rate': 3.199358187076582e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-100000\\config.json\n",
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-100000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6379, 'learning_rate': 3.019275997565289e-05, 'epoch': 0.4}\n",
      "{'loss': 0.6369, 'learning_rate': 2.839193808053996e-05, 'epoch': 0.43}\n",
      "{'loss': 0.6371, 'learning_rate': 2.659111618542703e-05, 'epoch': 0.47}\n",
      "{'loss': 0.6361, 'learning_rate': 2.47902942903141e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-150000\n",
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-150000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6335, 'learning_rate': 2.298947239520117e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-150000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6334, 'learning_rate': 2.118865050008824e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6331, 'learning_rate': 1.938782860497531e-05, 'epoch': 0.61}\n",
      "{'loss': 0.6335, 'learning_rate': 1.7587006709862385e-05, 'epoch': 0.65}\n",
      "{'loss': 0.6317, 'learning_rate': 1.5786184814749453e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6318, 'learning_rate': 1.3985362919636521e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-200000\\config.json\n",
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-200000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.632, 'learning_rate': 1.2184541024523593e-05, 'epoch': 0.76}\n",
      "{'loss': 0.6321, 'learning_rate': 1.0383719129410665e-05, 'epoch': 0.79}\n",
      "{'loss': 0.6297, 'learning_rate': 8.582897234297733e-06, 'epoch': 0.83}\n",
      "{'loss': 0.6309, 'learning_rate': 6.782075339184804e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/DistilGPT2\\checkpoint-250000\n",
      "Configuration saved in ./Models/DistilGPT2\\checkpoint-250000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6308, 'learning_rate': 4.981253444071874e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Models/DistilGPT2\\checkpoint-250000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6302, 'learning_rate': 3.1804315489589452e-06, 'epoch': 0.94}\n",
      "{'loss': 0.63, 'learning_rate': 1.3796096538460155e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 11295.2762, 'train_samples_per_second': 245.82, 'train_steps_per_second': 24.582, 'train_loss': 0.6407216623165254, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=277661, training_loss=0.6407216623165254, metrics={'train_runtime': 11295.2762, 'train_samples_per_second': 245.82, 'train_steps_per_second': 24.582, 'train_loss': 0.6407216623165254, 'epoch': 1.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n",
    "        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0] for f in data])}).train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/DistilGPT2\\config.json\n",
      "Model weights saved in ./Models/DistilGPT2\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save model and Tokenizer\n",
    "model.save_pretrained(\"./Models/DistilGPT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./Models/DistilGPT2\\tokenizer_config.json\n",
      "Special tokens file saved in ./Models/DistilGPT2\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Models/DistilGPT2\\\\tokenizer_config.json',\n",
       " './Models/DistilGPT2\\\\special_tokens_map.json',\n",
       " './Models/DistilGPT2\\\\vocab.json',\n",
       " './Models/DistilGPT2\\\\merges.txt',\n",
       " './Models/DistilGPT2\\\\added_tokens.json',\n",
       " './Models/DistilGPT2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./Models/DistilGPT2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in saved model and tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Models/DistilGPT2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./Models/DistilGPT2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: In view of the fading animals\n",
      "0:  In view of the fading animals\n",
      "1:  In view of the fading animals which\n",
      "2:  In view of the fading animals, I will only live for the\n",
      "3:  In view of the fading animals at its tail,\n",
      "4:  In view of the fading animals\n",
      "5:  In view of the fading animals the little flock of young,\n",
      "6:  In view of the fading animals.\n",
      "7:  In view of the fading animals\n",
      "8:  In view of the fading animals who wander and flee.\n",
      "9:  In view of the fading animals and the lost;\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"In view of the fading animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Shall I compare thee\n",
      "0:  Shall I compare thee in some respect not so\n",
      "1:  Shall I compare thee, with his art so dark\n",
      "2:  Shall I compare thee and the other?\n",
      "3:  Shall I compare thee, and tell his son to look in thee!\n",
      "4:  Shall I compare thee?\n",
      "5:  Shall I compare thee to me;\n",
      "6:  Shall I compare thee with thee\n",
      "7:  Shall I compare thee; and then shall thou see\n",
      "8:  Shall I compare thee more thy grace and my good,\n",
      "9:  Shall I compare thee for my son,\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"Shall I compare thee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness\n",
      "0:  Deep into that darkness beneath his heart!\n",
      "1:  Deep into that darkness in that bright hour, we knew\n",
      "2:  Deep into that darkness lay: the night of darkness on us to be\n",
      "3:  Deep into that darkness; a dream of life\n",
      "4:  Deep into that darkness,\n",
      "5:  Deep into that darkness he saw no face. No voice\n",
      "6:  Deep into that darkness, where the long night\n",
      "7:  Deep into that darkness his soul in the night falls;\n",
      "8:  Deep into that darkness lay its dark abyss;\n",
      "9:  Deep into that darkness they may not lie so long,\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"Deep into that darkness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "0:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I,\n",
      "1:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "2:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "3:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "4:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "5:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I.\n",
      "6:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "7:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "8:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "9:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n"
     ]
    }
   ],
   "source": [
    "long_prompt = 'Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I'\n",
    "\n",
    "generate_from_model(model, tokenizer, long_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: I stay\n",
      "0:  I stay too late to get away\n",
      "1:  I stay, in my arms the wind,\n",
      "2:  I stay to do his duty.\n",
      "3:  I stay awake on nights long,\n",
      "4:  I stay up for a day alone to have\n",
      "5:  I stay--no longer, no more?--you don't have much to think:\n",
      "6:  I stay so old and strong as a child,\n",
      "7:  I stay true to the man I loved--\n",
      "8:  I stay for nights, I pray till I see my Father--\n",
      "9:  I stay but never leave it, it shall always be,\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"I stay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The sunrise blaring the skies like a thousand stars;\n",
      "\n",
      "or more were there who made us, which, while\n",
      "\n",
      "all those who might have guessed at how\n",
      "\n",
      "in the day shall happen, from afar are things more\n",
      "\n",
      "wise? for you of that.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try and create more than one line at a time\n",
    "\n",
    "prompt = 'The sunrise'\n",
    "\n",
    "for i in range(5):\n",
    "    generated = tokenizer(\"<|startoftext|> \" + prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    sample_outputs = model.generate(generated, max_length=500, do_sample=True, top_p=0.95, top_k=50, temperature=1.9, num_return_sequences=1, pad_token_id=50256)\n",
    "\n",
    "    line = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    lastTwoWords = line.split()[-2:]\n",
    "\n",
    "    prompt = \" \".join(lastTwoWords)\n",
    "\n",
    "    if i == 0:\n",
    "        print(line + '\\n')\n",
    "    \n",
    "    else:\n",
    "        print(line.split(' ', 3)[3] + '\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model\n",
    "torch.manual_seed(92)\n",
    "\n",
    "MODEL_NAME = \"EleutherAI/gpt-neo-1.3B\"\n",
    "\n",
    "tokenizer_neo = AutoTokenizer.from_pretrained(MODEL_NAME, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "model_neo = AutoModelForCausalLM.from_pretrained(MODEL_NAME).cuda()\n",
    "model_neo.resize_token_embeddings(len(tokenizer_neo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traing arguments\n",
    "training_args_neo = TrainingArguments(output_dir='./Models/GPT-Neo', num_train_epochs=1, logging_steps=10000, save_steps=500000,\n",
    "                                  per_device_train_batch_size=10, per_device_eval_batch_size=10, warmup_steps=10,\n",
    "                                   weight_decay=0.05, logging_dir='./Models/GPT-Neo/logs', report_to='none' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(tokenizer_neo.encode(line)) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization_dataset = PoetryDataset(lines, tokenizer_neo, max_length=max_length)\n",
    "train_size = int(0.9  * len(tokenization_dataset))\n",
    "train_dataset_neo, val_dataset_neo = random_split(tokenization_dataset, [train_size, len(tokenization_dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50257,  3152,   257,  9480,  2786,   273,    11,   543,    11,   996,\n",
       "           284,   262,  4151, 50256, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_neo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training dataset: 2776605\n",
      "Length of Validation dataset: 308512\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of Training dataset: {len(train_dataset_neo)}\")\n",
    "print(f\"Length of Validation dataset: {len(val_dataset_neo)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight True\n",
      "transformer.wpe.weight True\n",
      "transformer.h.0.ln_1.weight True\n",
      "transformer.h.0.ln_1.bias True\n",
      "transformer.h.0.attn.attention.k_proj.weight True\n",
      "transformer.h.0.attn.attention.v_proj.weight True\n",
      "transformer.h.0.attn.attention.q_proj.weight True\n",
      "transformer.h.0.attn.attention.out_proj.weight True\n",
      "transformer.h.0.attn.attention.out_proj.bias True\n",
      "transformer.h.0.ln_2.weight True\n",
      "transformer.h.0.ln_2.bias True\n",
      "transformer.h.0.mlp.c_fc.weight True\n",
      "transformer.h.0.mlp.c_fc.bias True\n",
      "transformer.h.0.mlp.c_proj.weight True\n",
      "transformer.h.0.mlp.c_proj.bias True\n",
      "transformer.h.1.ln_1.weight True\n",
      "transformer.h.1.ln_1.bias True\n",
      "transformer.h.1.attn.attention.k_proj.weight True\n",
      "transformer.h.1.attn.attention.v_proj.weight True\n",
      "transformer.h.1.attn.attention.q_proj.weight True\n",
      "transformer.h.1.attn.attention.out_proj.weight True\n",
      "transformer.h.1.attn.attention.out_proj.bias True\n",
      "transformer.h.1.ln_2.weight True\n",
      "transformer.h.1.ln_2.bias True\n",
      "transformer.h.1.mlp.c_fc.weight True\n",
      "transformer.h.1.mlp.c_fc.bias True\n",
      "transformer.h.1.mlp.c_proj.weight True\n",
      "transformer.h.1.mlp.c_proj.bias True\n",
      "transformer.h.2.ln_1.weight True\n",
      "transformer.h.2.ln_1.bias True\n",
      "transformer.h.2.attn.attention.k_proj.weight True\n",
      "transformer.h.2.attn.attention.v_proj.weight True\n",
      "transformer.h.2.attn.attention.q_proj.weight True\n",
      "transformer.h.2.attn.attention.out_proj.weight True\n",
      "transformer.h.2.attn.attention.out_proj.bias True\n",
      "transformer.h.2.ln_2.weight True\n",
      "transformer.h.2.ln_2.bias True\n",
      "transformer.h.2.mlp.c_fc.weight True\n",
      "transformer.h.2.mlp.c_fc.bias True\n",
      "transformer.h.2.mlp.c_proj.weight True\n",
      "transformer.h.2.mlp.c_proj.bias True\n",
      "transformer.h.3.ln_1.weight True\n",
      "transformer.h.3.ln_1.bias True\n",
      "transformer.h.3.attn.attention.k_proj.weight True\n",
      "transformer.h.3.attn.attention.v_proj.weight True\n",
      "transformer.h.3.attn.attention.q_proj.weight True\n",
      "transformer.h.3.attn.attention.out_proj.weight True\n",
      "transformer.h.3.attn.attention.out_proj.bias True\n",
      "transformer.h.3.ln_2.weight True\n",
      "transformer.h.3.ln_2.bias True\n",
      "transformer.h.3.mlp.c_fc.weight True\n",
      "transformer.h.3.mlp.c_fc.bias True\n",
      "transformer.h.3.mlp.c_proj.weight True\n",
      "transformer.h.3.mlp.c_proj.bias True\n",
      "transformer.h.4.ln_1.weight True\n",
      "transformer.h.4.ln_1.bias True\n",
      "transformer.h.4.attn.attention.k_proj.weight True\n",
      "transformer.h.4.attn.attention.v_proj.weight True\n",
      "transformer.h.4.attn.attention.q_proj.weight True\n",
      "transformer.h.4.attn.attention.out_proj.weight True\n",
      "transformer.h.4.attn.attention.out_proj.bias True\n",
      "transformer.h.4.ln_2.weight True\n",
      "transformer.h.4.ln_2.bias True\n",
      "transformer.h.4.mlp.c_fc.weight True\n",
      "transformer.h.4.mlp.c_fc.bias True\n",
      "transformer.h.4.mlp.c_proj.weight True\n",
      "transformer.h.4.mlp.c_proj.bias True\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.attention.k_proj.weight True\n",
      "transformer.h.5.attn.attention.v_proj.weight True\n",
      "transformer.h.5.attn.attention.q_proj.weight True\n",
      "transformer.h.5.attn.attention.out_proj.weight True\n",
      "transformer.h.5.attn.attention.out_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.h.6.ln_1.weight True\n",
      "transformer.h.6.ln_1.bias True\n",
      "transformer.h.6.attn.attention.k_proj.weight True\n",
      "transformer.h.6.attn.attention.v_proj.weight True\n",
      "transformer.h.6.attn.attention.q_proj.weight True\n",
      "transformer.h.6.attn.attention.out_proj.weight True\n",
      "transformer.h.6.attn.attention.out_proj.bias True\n",
      "transformer.h.6.ln_2.weight True\n",
      "transformer.h.6.ln_2.bias True\n",
      "transformer.h.6.mlp.c_fc.weight True\n",
      "transformer.h.6.mlp.c_fc.bias True\n",
      "transformer.h.6.mlp.c_proj.weight True\n",
      "transformer.h.6.mlp.c_proj.bias True\n",
      "transformer.h.7.ln_1.weight True\n",
      "transformer.h.7.ln_1.bias True\n",
      "transformer.h.7.attn.attention.k_proj.weight True\n",
      "transformer.h.7.attn.attention.v_proj.weight True\n",
      "transformer.h.7.attn.attention.q_proj.weight True\n",
      "transformer.h.7.attn.attention.out_proj.weight True\n",
      "transformer.h.7.attn.attention.out_proj.bias True\n",
      "transformer.h.7.ln_2.weight True\n",
      "transformer.h.7.ln_2.bias True\n",
      "transformer.h.7.mlp.c_fc.weight True\n",
      "transformer.h.7.mlp.c_fc.bias True\n",
      "transformer.h.7.mlp.c_proj.weight True\n",
      "transformer.h.7.mlp.c_proj.bias True\n",
      "transformer.h.8.ln_1.weight True\n",
      "transformer.h.8.ln_1.bias True\n",
      "transformer.h.8.attn.attention.k_proj.weight True\n",
      "transformer.h.8.attn.attention.v_proj.weight True\n",
      "transformer.h.8.attn.attention.q_proj.weight True\n",
      "transformer.h.8.attn.attention.out_proj.weight True\n",
      "transformer.h.8.attn.attention.out_proj.bias True\n",
      "transformer.h.8.ln_2.weight True\n",
      "transformer.h.8.ln_2.bias True\n",
      "transformer.h.8.mlp.c_fc.weight True\n",
      "transformer.h.8.mlp.c_fc.bias True\n",
      "transformer.h.8.mlp.c_proj.weight True\n",
      "transformer.h.8.mlp.c_proj.bias True\n",
      "transformer.h.9.ln_1.weight True\n",
      "transformer.h.9.ln_1.bias True\n",
      "transformer.h.9.attn.attention.k_proj.weight True\n",
      "transformer.h.9.attn.attention.v_proj.weight True\n",
      "transformer.h.9.attn.attention.q_proj.weight True\n",
      "transformer.h.9.attn.attention.out_proj.weight True\n",
      "transformer.h.9.attn.attention.out_proj.bias True\n",
      "transformer.h.9.ln_2.weight True\n",
      "transformer.h.9.ln_2.bias True\n",
      "transformer.h.9.mlp.c_fc.weight True\n",
      "transformer.h.9.mlp.c_fc.bias True\n",
      "transformer.h.9.mlp.c_proj.weight True\n",
      "transformer.h.9.mlp.c_proj.bias True\n",
      "transformer.h.10.ln_1.weight True\n",
      "transformer.h.10.ln_1.bias True\n",
      "transformer.h.10.attn.attention.k_proj.weight True\n",
      "transformer.h.10.attn.attention.v_proj.weight True\n",
      "transformer.h.10.attn.attention.q_proj.weight True\n",
      "transformer.h.10.attn.attention.out_proj.weight True\n",
      "transformer.h.10.attn.attention.out_proj.bias True\n",
      "transformer.h.10.ln_2.weight True\n",
      "transformer.h.10.ln_2.bias True\n",
      "transformer.h.10.mlp.c_fc.weight True\n",
      "transformer.h.10.mlp.c_fc.bias True\n",
      "transformer.h.10.mlp.c_proj.weight True\n",
      "transformer.h.10.mlp.c_proj.bias True\n",
      "transformer.h.11.ln_1.weight True\n",
      "transformer.h.11.ln_1.bias True\n",
      "transformer.h.11.attn.attention.k_proj.weight True\n",
      "transformer.h.11.attn.attention.v_proj.weight True\n",
      "transformer.h.11.attn.attention.q_proj.weight True\n",
      "transformer.h.11.attn.attention.out_proj.weight True\n",
      "transformer.h.11.attn.attention.out_proj.bias True\n",
      "transformer.h.11.ln_2.weight True\n",
      "transformer.h.11.ln_2.bias True\n",
      "transformer.h.11.mlp.c_fc.weight True\n",
      "transformer.h.11.mlp.c_fc.bias True\n",
      "transformer.h.11.mlp.c_proj.weight True\n",
      "transformer.h.11.mlp.c_proj.bias True\n",
      "transformer.h.12.ln_1.weight True\n",
      "transformer.h.12.ln_1.bias True\n",
      "transformer.h.12.attn.attention.k_proj.weight True\n",
      "transformer.h.12.attn.attention.v_proj.weight True\n",
      "transformer.h.12.attn.attention.q_proj.weight True\n",
      "transformer.h.12.attn.attention.out_proj.weight True\n",
      "transformer.h.12.attn.attention.out_proj.bias True\n",
      "transformer.h.12.ln_2.weight True\n",
      "transformer.h.12.ln_2.bias True\n",
      "transformer.h.12.mlp.c_fc.weight True\n",
      "transformer.h.12.mlp.c_fc.bias True\n",
      "transformer.h.12.mlp.c_proj.weight True\n",
      "transformer.h.12.mlp.c_proj.bias True\n",
      "transformer.h.13.ln_1.weight True\n",
      "transformer.h.13.ln_1.bias True\n",
      "transformer.h.13.attn.attention.k_proj.weight True\n",
      "transformer.h.13.attn.attention.v_proj.weight True\n",
      "transformer.h.13.attn.attention.q_proj.weight True\n",
      "transformer.h.13.attn.attention.out_proj.weight True\n",
      "transformer.h.13.attn.attention.out_proj.bias True\n",
      "transformer.h.13.ln_2.weight True\n",
      "transformer.h.13.ln_2.bias True\n",
      "transformer.h.13.mlp.c_fc.weight True\n",
      "transformer.h.13.mlp.c_fc.bias True\n",
      "transformer.h.13.mlp.c_proj.weight True\n",
      "transformer.h.13.mlp.c_proj.bias True\n",
      "transformer.h.14.ln_1.weight True\n",
      "transformer.h.14.ln_1.bias True\n",
      "transformer.h.14.attn.attention.k_proj.weight True\n",
      "transformer.h.14.attn.attention.v_proj.weight True\n",
      "transformer.h.14.attn.attention.q_proj.weight True\n",
      "transformer.h.14.attn.attention.out_proj.weight True\n",
      "transformer.h.14.attn.attention.out_proj.bias True\n",
      "transformer.h.14.ln_2.weight True\n",
      "transformer.h.14.ln_2.bias True\n",
      "transformer.h.14.mlp.c_fc.weight True\n",
      "transformer.h.14.mlp.c_fc.bias True\n",
      "transformer.h.14.mlp.c_proj.weight True\n",
      "transformer.h.14.mlp.c_proj.bias True\n",
      "transformer.h.15.ln_1.weight True\n",
      "transformer.h.15.ln_1.bias True\n",
      "transformer.h.15.attn.attention.k_proj.weight True\n",
      "transformer.h.15.attn.attention.v_proj.weight True\n",
      "transformer.h.15.attn.attention.q_proj.weight True\n",
      "transformer.h.15.attn.attention.out_proj.weight True\n",
      "transformer.h.15.attn.attention.out_proj.bias True\n",
      "transformer.h.15.ln_2.weight True\n",
      "transformer.h.15.ln_2.bias True\n",
      "transformer.h.15.mlp.c_fc.weight True\n",
      "transformer.h.15.mlp.c_fc.bias True\n",
      "transformer.h.15.mlp.c_proj.weight True\n",
      "transformer.h.15.mlp.c_proj.bias True\n",
      "transformer.h.16.ln_1.weight True\n",
      "transformer.h.16.ln_1.bias True\n",
      "transformer.h.16.attn.attention.k_proj.weight True\n",
      "transformer.h.16.attn.attention.v_proj.weight True\n",
      "transformer.h.16.attn.attention.q_proj.weight True\n",
      "transformer.h.16.attn.attention.out_proj.weight True\n",
      "transformer.h.16.attn.attention.out_proj.bias True\n",
      "transformer.h.16.ln_2.weight True\n",
      "transformer.h.16.ln_2.bias True\n",
      "transformer.h.16.mlp.c_fc.weight True\n",
      "transformer.h.16.mlp.c_fc.bias True\n",
      "transformer.h.16.mlp.c_proj.weight True\n",
      "transformer.h.16.mlp.c_proj.bias True\n",
      "transformer.h.17.ln_1.weight True\n",
      "transformer.h.17.ln_1.bias True\n",
      "transformer.h.17.attn.attention.k_proj.weight True\n",
      "transformer.h.17.attn.attention.v_proj.weight True\n",
      "transformer.h.17.attn.attention.q_proj.weight True\n",
      "transformer.h.17.attn.attention.out_proj.weight True\n",
      "transformer.h.17.attn.attention.out_proj.bias True\n",
      "transformer.h.17.ln_2.weight True\n",
      "transformer.h.17.ln_2.bias True\n",
      "transformer.h.17.mlp.c_fc.weight True\n",
      "transformer.h.17.mlp.c_fc.bias True\n",
      "transformer.h.17.mlp.c_proj.weight True\n",
      "transformer.h.17.mlp.c_proj.bias True\n",
      "transformer.h.18.ln_1.weight True\n",
      "transformer.h.18.ln_1.bias True\n",
      "transformer.h.18.attn.attention.k_proj.weight True\n",
      "transformer.h.18.attn.attention.v_proj.weight True\n",
      "transformer.h.18.attn.attention.q_proj.weight True\n",
      "transformer.h.18.attn.attention.out_proj.weight True\n",
      "transformer.h.18.attn.attention.out_proj.bias True\n",
      "transformer.h.18.ln_2.weight True\n",
      "transformer.h.18.ln_2.bias True\n",
      "transformer.h.18.mlp.c_fc.weight True\n",
      "transformer.h.18.mlp.c_fc.bias True\n",
      "transformer.h.18.mlp.c_proj.weight True\n",
      "transformer.h.18.mlp.c_proj.bias True\n",
      "transformer.h.19.ln_1.weight True\n",
      "transformer.h.19.ln_1.bias True\n",
      "transformer.h.19.attn.attention.k_proj.weight True\n",
      "transformer.h.19.attn.attention.v_proj.weight True\n",
      "transformer.h.19.attn.attention.q_proj.weight True\n",
      "transformer.h.19.attn.attention.out_proj.weight True\n",
      "transformer.h.19.attn.attention.out_proj.bias True\n",
      "transformer.h.19.ln_2.weight True\n",
      "transformer.h.19.ln_2.bias True\n",
      "transformer.h.19.mlp.c_fc.weight True\n",
      "transformer.h.19.mlp.c_fc.bias True\n",
      "transformer.h.19.mlp.c_proj.weight True\n",
      "transformer.h.19.mlp.c_proj.bias True\n",
      "transformer.h.20.ln_1.weight True\n",
      "transformer.h.20.ln_1.bias True\n",
      "transformer.h.20.attn.attention.k_proj.weight True\n",
      "transformer.h.20.attn.attention.v_proj.weight True\n",
      "transformer.h.20.attn.attention.q_proj.weight True\n",
      "transformer.h.20.attn.attention.out_proj.weight True\n",
      "transformer.h.20.attn.attention.out_proj.bias True\n",
      "transformer.h.20.ln_2.weight True\n",
      "transformer.h.20.ln_2.bias True\n",
      "transformer.h.20.mlp.c_fc.weight True\n",
      "transformer.h.20.mlp.c_fc.bias True\n",
      "transformer.h.20.mlp.c_proj.weight True\n",
      "transformer.h.20.mlp.c_proj.bias True\n",
      "transformer.h.21.ln_1.weight True\n",
      "transformer.h.21.ln_1.bias True\n",
      "transformer.h.21.attn.attention.k_proj.weight True\n",
      "transformer.h.21.attn.attention.v_proj.weight True\n",
      "transformer.h.21.attn.attention.q_proj.weight True\n",
      "transformer.h.21.attn.attention.out_proj.weight True\n",
      "transformer.h.21.attn.attention.out_proj.bias True\n",
      "transformer.h.21.ln_2.weight True\n",
      "transformer.h.21.ln_2.bias True\n",
      "transformer.h.21.mlp.c_fc.weight True\n",
      "transformer.h.21.mlp.c_fc.bias True\n",
      "transformer.h.21.mlp.c_proj.weight True\n",
      "transformer.h.21.mlp.c_proj.bias True\n",
      "transformer.h.22.ln_1.weight True\n",
      "transformer.h.22.ln_1.bias True\n",
      "transformer.h.22.attn.attention.k_proj.weight True\n",
      "transformer.h.22.attn.attention.v_proj.weight True\n",
      "transformer.h.22.attn.attention.q_proj.weight True\n",
      "transformer.h.22.attn.attention.out_proj.weight True\n",
      "transformer.h.22.attn.attention.out_proj.bias True\n",
      "transformer.h.22.ln_2.weight True\n",
      "transformer.h.22.ln_2.bias True\n",
      "transformer.h.22.mlp.c_fc.weight True\n",
      "transformer.h.22.mlp.c_fc.bias True\n",
      "transformer.h.22.mlp.c_proj.weight True\n",
      "transformer.h.22.mlp.c_proj.bias True\n",
      "transformer.h.23.ln_1.weight True\n",
      "transformer.h.23.ln_1.bias True\n",
      "transformer.h.23.attn.attention.k_proj.weight True\n",
      "transformer.h.23.attn.attention.v_proj.weight True\n",
      "transformer.h.23.attn.attention.q_proj.weight True\n",
      "transformer.h.23.attn.attention.out_proj.weight True\n",
      "transformer.h.23.attn.attention.out_proj.bias True\n",
      "transformer.h.23.ln_2.weight True\n",
      "transformer.h.23.ln_2.bias True\n",
      "transformer.h.23.mlp.c_fc.weight True\n",
      "transformer.h.23.mlp.c_fc.bias True\n",
      "transformer.h.23.mlp.c_proj.weight True\n",
      "transformer.h.23.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_neo.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the first two layers and 23 hidden units\n",
    "for name, param in model_neo.named_parameters():\n",
    "    if name.startswith(\"transformer.wte\"):\n",
    "        param.requires_grad = False\n",
    "    if name.startswith(\"transformer.wpe\"):\n",
    "        param.requires_grad = False\n",
    "    if any(x in name for x in ['.' + str(x) + '.' for x in range(23)]):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight False\n",
      "transformer.wpe.weight False\n",
      "transformer.h.0.ln_1.weight False\n",
      "transformer.h.0.ln_1.bias False\n",
      "transformer.h.0.attn.attention.k_proj.weight False\n",
      "transformer.h.0.attn.attention.v_proj.weight False\n",
      "transformer.h.0.attn.attention.q_proj.weight False\n",
      "transformer.h.0.attn.attention.out_proj.weight False\n",
      "transformer.h.0.attn.attention.out_proj.bias False\n",
      "transformer.h.0.ln_2.weight False\n",
      "transformer.h.0.ln_2.bias False\n",
      "transformer.h.0.mlp.c_fc.weight False\n",
      "transformer.h.0.mlp.c_fc.bias False\n",
      "transformer.h.0.mlp.c_proj.weight False\n",
      "transformer.h.0.mlp.c_proj.bias False\n",
      "transformer.h.1.ln_1.weight False\n",
      "transformer.h.1.ln_1.bias False\n",
      "transformer.h.1.attn.attention.k_proj.weight False\n",
      "transformer.h.1.attn.attention.v_proj.weight False\n",
      "transformer.h.1.attn.attention.q_proj.weight False\n",
      "transformer.h.1.attn.attention.out_proj.weight False\n",
      "transformer.h.1.attn.attention.out_proj.bias False\n",
      "transformer.h.1.ln_2.weight False\n",
      "transformer.h.1.ln_2.bias False\n",
      "transformer.h.1.mlp.c_fc.weight False\n",
      "transformer.h.1.mlp.c_fc.bias False\n",
      "transformer.h.1.mlp.c_proj.weight False\n",
      "transformer.h.1.mlp.c_proj.bias False\n",
      "transformer.h.2.ln_1.weight False\n",
      "transformer.h.2.ln_1.bias False\n",
      "transformer.h.2.attn.attention.k_proj.weight False\n",
      "transformer.h.2.attn.attention.v_proj.weight False\n",
      "transformer.h.2.attn.attention.q_proj.weight False\n",
      "transformer.h.2.attn.attention.out_proj.weight False\n",
      "transformer.h.2.attn.attention.out_proj.bias False\n",
      "transformer.h.2.ln_2.weight False\n",
      "transformer.h.2.ln_2.bias False\n",
      "transformer.h.2.mlp.c_fc.weight False\n",
      "transformer.h.2.mlp.c_fc.bias False\n",
      "transformer.h.2.mlp.c_proj.weight False\n",
      "transformer.h.2.mlp.c_proj.bias False\n",
      "transformer.h.3.ln_1.weight False\n",
      "transformer.h.3.ln_1.bias False\n",
      "transformer.h.3.attn.attention.k_proj.weight False\n",
      "transformer.h.3.attn.attention.v_proj.weight False\n",
      "transformer.h.3.attn.attention.q_proj.weight False\n",
      "transformer.h.3.attn.attention.out_proj.weight False\n",
      "transformer.h.3.attn.attention.out_proj.bias False\n",
      "transformer.h.3.ln_2.weight False\n",
      "transformer.h.3.ln_2.bias False\n",
      "transformer.h.3.mlp.c_fc.weight False\n",
      "transformer.h.3.mlp.c_fc.bias False\n",
      "transformer.h.3.mlp.c_proj.weight False\n",
      "transformer.h.3.mlp.c_proj.bias False\n",
      "transformer.h.4.ln_1.weight False\n",
      "transformer.h.4.ln_1.bias False\n",
      "transformer.h.4.attn.attention.k_proj.weight False\n",
      "transformer.h.4.attn.attention.v_proj.weight False\n",
      "transformer.h.4.attn.attention.q_proj.weight False\n",
      "transformer.h.4.attn.attention.out_proj.weight False\n",
      "transformer.h.4.attn.attention.out_proj.bias False\n",
      "transformer.h.4.ln_2.weight False\n",
      "transformer.h.4.ln_2.bias False\n",
      "transformer.h.4.mlp.c_fc.weight False\n",
      "transformer.h.4.mlp.c_fc.bias False\n",
      "transformer.h.4.mlp.c_proj.weight False\n",
      "transformer.h.4.mlp.c_proj.bias False\n",
      "transformer.h.5.ln_1.weight False\n",
      "transformer.h.5.ln_1.bias False\n",
      "transformer.h.5.attn.attention.k_proj.weight False\n",
      "transformer.h.5.attn.attention.v_proj.weight False\n",
      "transformer.h.5.attn.attention.q_proj.weight False\n",
      "transformer.h.5.attn.attention.out_proj.weight False\n",
      "transformer.h.5.attn.attention.out_proj.bias False\n",
      "transformer.h.5.ln_2.weight False\n",
      "transformer.h.5.ln_2.bias False\n",
      "transformer.h.5.mlp.c_fc.weight False\n",
      "transformer.h.5.mlp.c_fc.bias False\n",
      "transformer.h.5.mlp.c_proj.weight False\n",
      "transformer.h.5.mlp.c_proj.bias False\n",
      "transformer.h.6.ln_1.weight False\n",
      "transformer.h.6.ln_1.bias False\n",
      "transformer.h.6.attn.attention.k_proj.weight False\n",
      "transformer.h.6.attn.attention.v_proj.weight False\n",
      "transformer.h.6.attn.attention.q_proj.weight False\n",
      "transformer.h.6.attn.attention.out_proj.weight False\n",
      "transformer.h.6.attn.attention.out_proj.bias False\n",
      "transformer.h.6.ln_2.weight False\n",
      "transformer.h.6.ln_2.bias False\n",
      "transformer.h.6.mlp.c_fc.weight False\n",
      "transformer.h.6.mlp.c_fc.bias False\n",
      "transformer.h.6.mlp.c_proj.weight False\n",
      "transformer.h.6.mlp.c_proj.bias False\n",
      "transformer.h.7.ln_1.weight False\n",
      "transformer.h.7.ln_1.bias False\n",
      "transformer.h.7.attn.attention.k_proj.weight False\n",
      "transformer.h.7.attn.attention.v_proj.weight False\n",
      "transformer.h.7.attn.attention.q_proj.weight False\n",
      "transformer.h.7.attn.attention.out_proj.weight False\n",
      "transformer.h.7.attn.attention.out_proj.bias False\n",
      "transformer.h.7.ln_2.weight False\n",
      "transformer.h.7.ln_2.bias False\n",
      "transformer.h.7.mlp.c_fc.weight False\n",
      "transformer.h.7.mlp.c_fc.bias False\n",
      "transformer.h.7.mlp.c_proj.weight False\n",
      "transformer.h.7.mlp.c_proj.bias False\n",
      "transformer.h.8.ln_1.weight False\n",
      "transformer.h.8.ln_1.bias False\n",
      "transformer.h.8.attn.attention.k_proj.weight False\n",
      "transformer.h.8.attn.attention.v_proj.weight False\n",
      "transformer.h.8.attn.attention.q_proj.weight False\n",
      "transformer.h.8.attn.attention.out_proj.weight False\n",
      "transformer.h.8.attn.attention.out_proj.bias False\n",
      "transformer.h.8.ln_2.weight False\n",
      "transformer.h.8.ln_2.bias False\n",
      "transformer.h.8.mlp.c_fc.weight False\n",
      "transformer.h.8.mlp.c_fc.bias False\n",
      "transformer.h.8.mlp.c_proj.weight False\n",
      "transformer.h.8.mlp.c_proj.bias False\n",
      "transformer.h.9.ln_1.weight False\n",
      "transformer.h.9.ln_1.bias False\n",
      "transformer.h.9.attn.attention.k_proj.weight False\n",
      "transformer.h.9.attn.attention.v_proj.weight False\n",
      "transformer.h.9.attn.attention.q_proj.weight False\n",
      "transformer.h.9.attn.attention.out_proj.weight False\n",
      "transformer.h.9.attn.attention.out_proj.bias False\n",
      "transformer.h.9.ln_2.weight False\n",
      "transformer.h.9.ln_2.bias False\n",
      "transformer.h.9.mlp.c_fc.weight False\n",
      "transformer.h.9.mlp.c_fc.bias False\n",
      "transformer.h.9.mlp.c_proj.weight False\n",
      "transformer.h.9.mlp.c_proj.bias False\n",
      "transformer.h.10.ln_1.weight False\n",
      "transformer.h.10.ln_1.bias False\n",
      "transformer.h.10.attn.attention.k_proj.weight False\n",
      "transformer.h.10.attn.attention.v_proj.weight False\n",
      "transformer.h.10.attn.attention.q_proj.weight False\n",
      "transformer.h.10.attn.attention.out_proj.weight False\n",
      "transformer.h.10.attn.attention.out_proj.bias False\n",
      "transformer.h.10.ln_2.weight False\n",
      "transformer.h.10.ln_2.bias False\n",
      "transformer.h.10.mlp.c_fc.weight False\n",
      "transformer.h.10.mlp.c_fc.bias False\n",
      "transformer.h.10.mlp.c_proj.weight False\n",
      "transformer.h.10.mlp.c_proj.bias False\n",
      "transformer.h.11.ln_1.weight False\n",
      "transformer.h.11.ln_1.bias False\n",
      "transformer.h.11.attn.attention.k_proj.weight False\n",
      "transformer.h.11.attn.attention.v_proj.weight False\n",
      "transformer.h.11.attn.attention.q_proj.weight False\n",
      "transformer.h.11.attn.attention.out_proj.weight False\n",
      "transformer.h.11.attn.attention.out_proj.bias False\n",
      "transformer.h.11.ln_2.weight False\n",
      "transformer.h.11.ln_2.bias False\n",
      "transformer.h.11.mlp.c_fc.weight False\n",
      "transformer.h.11.mlp.c_fc.bias False\n",
      "transformer.h.11.mlp.c_proj.weight False\n",
      "transformer.h.11.mlp.c_proj.bias False\n",
      "transformer.h.12.ln_1.weight False\n",
      "transformer.h.12.ln_1.bias False\n",
      "transformer.h.12.attn.attention.k_proj.weight False\n",
      "transformer.h.12.attn.attention.v_proj.weight False\n",
      "transformer.h.12.attn.attention.q_proj.weight False\n",
      "transformer.h.12.attn.attention.out_proj.weight False\n",
      "transformer.h.12.attn.attention.out_proj.bias False\n",
      "transformer.h.12.ln_2.weight False\n",
      "transformer.h.12.ln_2.bias False\n",
      "transformer.h.12.mlp.c_fc.weight False\n",
      "transformer.h.12.mlp.c_fc.bias False\n",
      "transformer.h.12.mlp.c_proj.weight False\n",
      "transformer.h.12.mlp.c_proj.bias False\n",
      "transformer.h.13.ln_1.weight False\n",
      "transformer.h.13.ln_1.bias False\n",
      "transformer.h.13.attn.attention.k_proj.weight False\n",
      "transformer.h.13.attn.attention.v_proj.weight False\n",
      "transformer.h.13.attn.attention.q_proj.weight False\n",
      "transformer.h.13.attn.attention.out_proj.weight False\n",
      "transformer.h.13.attn.attention.out_proj.bias False\n",
      "transformer.h.13.ln_2.weight False\n",
      "transformer.h.13.ln_2.bias False\n",
      "transformer.h.13.mlp.c_fc.weight False\n",
      "transformer.h.13.mlp.c_fc.bias False\n",
      "transformer.h.13.mlp.c_proj.weight False\n",
      "transformer.h.13.mlp.c_proj.bias False\n",
      "transformer.h.14.ln_1.weight False\n",
      "transformer.h.14.ln_1.bias False\n",
      "transformer.h.14.attn.attention.k_proj.weight False\n",
      "transformer.h.14.attn.attention.v_proj.weight False\n",
      "transformer.h.14.attn.attention.q_proj.weight False\n",
      "transformer.h.14.attn.attention.out_proj.weight False\n",
      "transformer.h.14.attn.attention.out_proj.bias False\n",
      "transformer.h.14.ln_2.weight False\n",
      "transformer.h.14.ln_2.bias False\n",
      "transformer.h.14.mlp.c_fc.weight False\n",
      "transformer.h.14.mlp.c_fc.bias False\n",
      "transformer.h.14.mlp.c_proj.weight False\n",
      "transformer.h.14.mlp.c_proj.bias False\n",
      "transformer.h.15.ln_1.weight False\n",
      "transformer.h.15.ln_1.bias False\n",
      "transformer.h.15.attn.attention.k_proj.weight False\n",
      "transformer.h.15.attn.attention.v_proj.weight False\n",
      "transformer.h.15.attn.attention.q_proj.weight False\n",
      "transformer.h.15.attn.attention.out_proj.weight False\n",
      "transformer.h.15.attn.attention.out_proj.bias False\n",
      "transformer.h.15.ln_2.weight False\n",
      "transformer.h.15.ln_2.bias False\n",
      "transformer.h.15.mlp.c_fc.weight False\n",
      "transformer.h.15.mlp.c_fc.bias False\n",
      "transformer.h.15.mlp.c_proj.weight False\n",
      "transformer.h.15.mlp.c_proj.bias False\n",
      "transformer.h.16.ln_1.weight False\n",
      "transformer.h.16.ln_1.bias False\n",
      "transformer.h.16.attn.attention.k_proj.weight False\n",
      "transformer.h.16.attn.attention.v_proj.weight False\n",
      "transformer.h.16.attn.attention.q_proj.weight False\n",
      "transformer.h.16.attn.attention.out_proj.weight False\n",
      "transformer.h.16.attn.attention.out_proj.bias False\n",
      "transformer.h.16.ln_2.weight False\n",
      "transformer.h.16.ln_2.bias False\n",
      "transformer.h.16.mlp.c_fc.weight False\n",
      "transformer.h.16.mlp.c_fc.bias False\n",
      "transformer.h.16.mlp.c_proj.weight False\n",
      "transformer.h.16.mlp.c_proj.bias False\n",
      "transformer.h.17.ln_1.weight False\n",
      "transformer.h.17.ln_1.bias False\n",
      "transformer.h.17.attn.attention.k_proj.weight False\n",
      "transformer.h.17.attn.attention.v_proj.weight False\n",
      "transformer.h.17.attn.attention.q_proj.weight False\n",
      "transformer.h.17.attn.attention.out_proj.weight False\n",
      "transformer.h.17.attn.attention.out_proj.bias False\n",
      "transformer.h.17.ln_2.weight False\n",
      "transformer.h.17.ln_2.bias False\n",
      "transformer.h.17.mlp.c_fc.weight False\n",
      "transformer.h.17.mlp.c_fc.bias False\n",
      "transformer.h.17.mlp.c_proj.weight False\n",
      "transformer.h.17.mlp.c_proj.bias False\n",
      "transformer.h.18.ln_1.weight False\n",
      "transformer.h.18.ln_1.bias False\n",
      "transformer.h.18.attn.attention.k_proj.weight False\n",
      "transformer.h.18.attn.attention.v_proj.weight False\n",
      "transformer.h.18.attn.attention.q_proj.weight False\n",
      "transformer.h.18.attn.attention.out_proj.weight False\n",
      "transformer.h.18.attn.attention.out_proj.bias False\n",
      "transformer.h.18.ln_2.weight False\n",
      "transformer.h.18.ln_2.bias False\n",
      "transformer.h.18.mlp.c_fc.weight False\n",
      "transformer.h.18.mlp.c_fc.bias False\n",
      "transformer.h.18.mlp.c_proj.weight False\n",
      "transformer.h.18.mlp.c_proj.bias False\n",
      "transformer.h.19.ln_1.weight False\n",
      "transformer.h.19.ln_1.bias False\n",
      "transformer.h.19.attn.attention.k_proj.weight False\n",
      "transformer.h.19.attn.attention.v_proj.weight False\n",
      "transformer.h.19.attn.attention.q_proj.weight False\n",
      "transformer.h.19.attn.attention.out_proj.weight False\n",
      "transformer.h.19.attn.attention.out_proj.bias False\n",
      "transformer.h.19.ln_2.weight False\n",
      "transformer.h.19.ln_2.bias False\n",
      "transformer.h.19.mlp.c_fc.weight False\n",
      "transformer.h.19.mlp.c_fc.bias False\n",
      "transformer.h.19.mlp.c_proj.weight False\n",
      "transformer.h.19.mlp.c_proj.bias False\n",
      "transformer.h.20.ln_1.weight False\n",
      "transformer.h.20.ln_1.bias False\n",
      "transformer.h.20.attn.attention.k_proj.weight False\n",
      "transformer.h.20.attn.attention.v_proj.weight False\n",
      "transformer.h.20.attn.attention.q_proj.weight False\n",
      "transformer.h.20.attn.attention.out_proj.weight False\n",
      "transformer.h.20.attn.attention.out_proj.bias False\n",
      "transformer.h.20.ln_2.weight False\n",
      "transformer.h.20.ln_2.bias False\n",
      "transformer.h.20.mlp.c_fc.weight False\n",
      "transformer.h.20.mlp.c_fc.bias False\n",
      "transformer.h.20.mlp.c_proj.weight False\n",
      "transformer.h.20.mlp.c_proj.bias False\n",
      "transformer.h.21.ln_1.weight False\n",
      "transformer.h.21.ln_1.bias False\n",
      "transformer.h.21.attn.attention.k_proj.weight False\n",
      "transformer.h.21.attn.attention.v_proj.weight False\n",
      "transformer.h.21.attn.attention.q_proj.weight False\n",
      "transformer.h.21.attn.attention.out_proj.weight False\n",
      "transformer.h.21.attn.attention.out_proj.bias False\n",
      "transformer.h.21.ln_2.weight False\n",
      "transformer.h.21.ln_2.bias False\n",
      "transformer.h.21.mlp.c_fc.weight False\n",
      "transformer.h.21.mlp.c_fc.bias False\n",
      "transformer.h.21.mlp.c_proj.weight False\n",
      "transformer.h.21.mlp.c_proj.bias False\n",
      "transformer.h.22.ln_1.weight False\n",
      "transformer.h.22.ln_1.bias False\n",
      "transformer.h.22.attn.attention.k_proj.weight False\n",
      "transformer.h.22.attn.attention.v_proj.weight False\n",
      "transformer.h.22.attn.attention.q_proj.weight False\n",
      "transformer.h.22.attn.attention.out_proj.weight False\n",
      "transformer.h.22.attn.attention.out_proj.bias False\n",
      "transformer.h.22.ln_2.weight False\n",
      "transformer.h.22.ln_2.bias False\n",
      "transformer.h.22.mlp.c_fc.weight False\n",
      "transformer.h.22.mlp.c_fc.bias False\n",
      "transformer.h.22.mlp.c_proj.weight False\n",
      "transformer.h.22.mlp.c_proj.bias False\n",
      "transformer.h.23.ln_1.weight True\n",
      "transformer.h.23.ln_1.bias True\n",
      "transformer.h.23.attn.attention.k_proj.weight True\n",
      "transformer.h.23.attn.attention.v_proj.weight True\n",
      "transformer.h.23.attn.attention.q_proj.weight True\n",
      "transformer.h.23.attn.attention.out_proj.weight True\n",
      "transformer.h.23.attn.attention.out_proj.bias True\n",
      "transformer.h.23.ln_2.weight True\n",
      "transformer.h.23.ln_2.bias True\n",
      "transformer.h.23.mlp.c_fc.weight True\n",
      "transformer.h.23.mlp.c_fc.bias True\n",
      "transformer.h.23.mlp.c_proj.weight True\n",
      "transformer.h.23.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "# check layers\n",
    "for name, param in model_neo.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shayne Kaiser\\anaconda3\\envs\\poetryproject\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2776605\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 277661\n",
      "  Number of trainable parameters = 50356224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa88b8d6f7e84973ac677e7a59b0d559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/277661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8757, 'learning_rate': 4.8200978926782185e-05, 'epoch': 0.04}\n",
      "{'loss': 0.8238, 'learning_rate': 4.640015703166925e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8112, 'learning_rate': 4.459933513655633e-05, 'epoch': 0.11}\n",
      "{'loss': 0.8019, 'learning_rate': 4.27985132414434e-05, 'epoch': 0.14}\n",
      "{'loss': 0.7945, 'learning_rate': 4.099769134633047e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7902, 'learning_rate': 3.919686945121754e-05, 'epoch': 0.22}\n",
      "{'loss': 0.7844, 'learning_rate': 3.739604755610461e-05, 'epoch': 0.25}\n",
      "{'loss': 0.7811, 'learning_rate': 3.559522566099168e-05, 'epoch': 0.29}\n",
      "{'loss': 0.7778, 'learning_rate': 3.3794403765878745e-05, 'epoch': 0.32}\n",
      "{'loss': 0.7751, 'learning_rate': 3.199358187076582e-05, 'epoch': 0.36}\n",
      "{'loss': 0.7725, 'learning_rate': 3.019275997565289e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7696, 'learning_rate': 2.839193808053996e-05, 'epoch': 0.43}\n",
      "{'loss': 0.7676, 'learning_rate': 2.659111618542703e-05, 'epoch': 0.47}\n",
      "{'loss': 0.7668, 'learning_rate': 2.47902942903141e-05, 'epoch': 0.5}\n",
      "{'loss': 0.7636, 'learning_rate': 2.298947239520117e-05, 'epoch': 0.54}\n",
      "{'loss': 0.7623, 'learning_rate': 2.118865050008824e-05, 'epoch': 0.58}\n",
      "{'loss': 0.7599, 'learning_rate': 1.938782860497531e-05, 'epoch': 0.61}\n",
      "{'loss': 0.7588, 'learning_rate': 1.7587006709862385e-05, 'epoch': 0.65}\n",
      "{'loss': 0.758, 'learning_rate': 1.5786184814749453e-05, 'epoch': 0.68}\n",
      "{'loss': 0.7573, 'learning_rate': 1.3985362919636521e-05, 'epoch': 0.72}\n",
      "{'loss': 0.7553, 'learning_rate': 1.2184541024523593e-05, 'epoch': 0.76}\n",
      "{'loss': 0.7539, 'learning_rate': 1.0383719129410665e-05, 'epoch': 0.79}\n",
      "{'loss': 0.7536, 'learning_rate': 8.582897234297733e-06, 'epoch': 0.83}\n",
      "{'loss': 0.7511, 'learning_rate': 6.782075339184804e-06, 'epoch': 0.86}\n",
      "{'loss': 0.752, 'learning_rate': 4.981253444071874e-06, 'epoch': 0.9}\n",
      "{'loss': 0.7505, 'learning_rate': 3.1804315489589452e-06, 'epoch': 0.94}\n",
      "{'loss': 0.7505, 'learning_rate': 1.3796096538460155e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 123748.8893, 'train_samples_per_second': 22.437, 'train_steps_per_second': 2.244, 'train_loss': 0.7741056002052638, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=277661, training_loss=0.7741056002052638, metrics={'train_runtime': 123748.8893, 'train_samples_per_second': 22.437, 'train_steps_per_second': 2.244, 'train_loss': 0.7741056002052638, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainer(model=model_neo,  args=training_args_neo, train_dataset=train_dataset_neo, \n",
    "        eval_dataset=val_dataset_neo, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0] for f in data])}).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/GPT-Neo\\config.json\n",
      "Model weights saved in ./Models/GPT-Neo\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save model and Tokenizer\n",
    "model_neo.save_pretrained(\"./Models/GPT-Neo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./Models/GPT-Neo\\tokenizer_config.json\n",
      "Special tokens file saved in ./Models/GPT-Neo\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Models/GPT-Neo\\\\tokenizer_config.json',\n",
       " './Models/GPT-Neo\\\\special_tokens_map.json',\n",
       " './Models/GPT-Neo\\\\vocab.json',\n",
       " './Models/GPT-Neo\\\\merges.txt',\n",
       " './Models/GPT-Neo\\\\added_tokens.json',\n",
       " './Models/GPT-Neo\\\\tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_neo.save_pretrained(\"./Models/GPT-Neo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in saved model and tokenizer \n",
    "tokenizer_neo = AutoTokenizer.from_pretrained(\"./Models/GPT-Neo\")\n",
    "model_neo = AutoModelForCausalLM.from_pretrained(\"./Models/GPT-Neo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: In view of the fading animals\n",
      "0:  In view of the fading animals.\n",
      "1:  In view of the fading animals to\n",
      "2:  In view of the fading animals with his eye!\n",
      "3:  In view of the fading animals, \"with. a new\n",
      "4:  In view of the fading animals that he he been the nighthe on;\n",
      "5:  In view of the fading animals.' in the to no by. I,\n",
      "6:  In view of the fading animals,\n",
      "7:  In view of the fading animals is our\n",
      "8:  In view of the fading animals;\n",
      "9:  In view of the fading animals of the same:\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model_neo, tokenizer_neo, \"In view of the fading animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Shall I compare thee\n",
      "0:  Shall I compare thee he did the earth and still\n",
      "1:  Shall I compare thee-e the light is they thought youre-like the\n",
      "2:  Shall I compare thee thou on thee be.\n",
      "3:  Shall I compare thee the words, and her life\n",
      "4:  Shall I compare thee, I said; I in life was, of\n",
      "5:  Shall I compare thee in your soul from each me the sea\n",
      "6:  Shall I compare thee! and I shall come see had it me:?\n",
      "7:  Shall I compare thee the years He--\n",
      "8:  Shall I compare thee\n",
      "9:  Shall I compare thee for But who voice it?\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model_neo, tokenizer_neo, \"Shall I compare thee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness\n",
      "0:  Deep into that darkness that never sees--and knows--.\"\n",
      "1:  Deep into that darkness.\"  He paused then:\n",
      "2:  Deep into that darkness, with the sea waves,\n",
      "3:  Deep into that darkness, and his blood a mist in her,\n",
      "4:  Deep into that darkness the darkness. I stand;\n",
      "5:  Deep into that darkness in that sky?...\n",
      "6:  Deep into that darkness\n",
      "7:  Deep into that darkness,--who at this moment\n",
      "8:  Deep into that darkness; and this life\n",
      "9:  Deep into that darkness\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model, tokenizer, \"Deep into that darkness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "0:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "1:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I.\n",
      "2:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "3:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "4:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "5:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "6:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "7:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "8:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "9:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I,\n"
     ]
    }
   ],
   "source": [
    "long_prompt = 'Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I'\n",
    "\n",
    "generate_from_model(model, tokenizer, long_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Whole Poems with DistilGPT2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe that combines 25 lines at a time\n",
    "\n",
    "df_list = df['line'].tolist()\n",
    "\n",
    "split_list = list()\n",
    "split_size = 25\n",
    "\n",
    "for i in range(0, len(df_list), split_size):\n",
    "    split_list.append(df_list[i:i+split_size])\n",
    "\n",
    "for i in range(0, len(split_list)):\n",
    "    split_list[i] = ' '.join(split_list[i])\n",
    "\n",
    "df_longer_lines = pd.DataFrame(split_list, columns=['line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Son of God to judge them, terrifi'd Hee fled, not hoping to escape, but shun The present, fearing guiltie what his wrauth Might suddenly inflict; that past, return'd By Night, and listning where the hapless Paire Sate in thir sad discourse, and various plaint, Thence gatherd his own doom, which understood Not instant, but of future time.  With joy And tidings fraught, to Hell he now return'd, And at the brink of CHAOS, neer the foot Of this new wondrous Pontifice, unhop't Met who to meet him came, his Ofspring dear. Great joy was at thir meeting, and at sight Of that stupendious Bridge his joy encreas'd. Long hee admiring stood, till Sin, his faire Inchanting Daughter, thus the silence broke. O Parent, these are thy magnific deeds, Thy Trophies, which thou view'st as not thine own, Thou art thir Author and prime Architect: For I no sooner in my Heart divin'd, My Heart, which by a secret harmonie Still moves with thine, joyn'd in connexion sweet, That thou on Earth hadst prosper'd, which thy looks Now also evidence, but straight I felt Though distant from thee Worlds between, yet felt\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_longer_lines['line'].iloc[542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123405, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df_longer_lines.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         The Song of Hiawatha is based on the legends a...\n",
       "1         Little, flitting, white-fire insect Little, da...\n",
       "2         Should you ask where Nawadaha Found these song...\n",
       "3         And beyond them stood the forest, Stood the gr...\n",
       "4         Through their palisades of pine-trees, And the...\n",
       "                                ...                        \n",
       "123400    Pepulitque noctis umbras vegetis sonipedibus. ...\n",
       "123401    Tempe quae silvae cingunt super inpendentes,--...\n",
       "123402    Lux mea qua viva vivere dulce mihi'st. In this...\n",
       "123403    Oh then, full surely thy Quintilia's woe. For ...\n",
       "123404    And his face the index be, Of his mother's cha...\n",
       "Name: line, Length: 123405, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_lines = df_longer_lines['line']\n",
    "longer_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model\n",
    "# using distilgpt2 again because it's faster to train\n",
    "torch.manual_seed(92)\n",
    "\n",
    "MODEL_NAME = \"distilgpt2\"\n",
    "\n",
    "tokenizer_poem = AutoTokenizer.from_pretrained(MODEL_NAME, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "model_poem = AutoModelForCausalLM.from_pretrained(MODEL_NAME).cuda()\n",
    "model_poem.resize_token_embeddings(len(tokenizer_poem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./Models/PoemDistil', num_train_epochs=1, logging_steps=10000, save_steps=50000,\n",
    "                                  per_device_train_batch_size=1, per_device_eval_batch_size=1, warmup_steps=10,\n",
    "                                   weight_decay=0.05, logging_dir='./Models/PoemDistil/logs', report_to='none' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(tokenizer_poem.encode(line)) for line in longer_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "965"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenization_dataset = PoetryDataset(longer_lines, tokenizer_poem, max_length=max_length)\n",
    "train_size = int(0.9  * len(tokenization_dataset))\n",
    "train_dataset, val_dataset = random_split(tokenization_dataset, [train_size, len(tokenization_dataset) - train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([50257,  2504,   340,   318,   477,   465,  8716,   290, 20788, 11459,\n",
       "           373,   262,  1110,    11,   355,   314,   423,  1297,   304,   260,\n",
       "           428,    11,   843,  2312,   385,    11,   351, 28654,  8716,   290,\n",
       "         30533,    11,  2080,   465, 33812,  3366,  8326,    11,   262, 37063,\n",
       "         16599,    11,   843, 17608,    11,   331,    12,   565,   313,   704,\n",
       "           477,   287,  4077,    11,  1550, 10988,   307,   484, 46715, 10611,\n",
       "           453,    13,   843,   284,   262,  7128,   303,    11,   326,  6204,\n",
       "           612,  3049,    68,   416,    11,   554,   543,   612,   373,   281,\n",
       "           289,   433,    11,   355,  1450,   683,  1297,    11, 11083,  2312,\n",
       "           385,   262,  3892,    68,   835,   288,   849,  1745,    11,   843,\n",
       "           625,   257,  1379,   482,    11,   290,   523,  6071,   319,   465,\n",
       "           835,    13,   770, 11083,   481,   423,   257,  1781,   379,   683,\n",
       "           393,   665,   323,  4698,   262,  4252,   339,  3114,    11,   290,\n",
       "           281,   261,   679,   373, 16202,   286, 10173,   578,   290,  3175,\n",
       "         16487,    11,  1406,  7808,  3481,    11,   326,   351,   262,  1551,\n",
       "            68, 14000,   632,  3947,   326,   340,   561,    68,  3214,   281,\n",
       "         26210,    11,  1400,   517,    11,   319,  2356,   286,  6078,   286,\n",
       "           534,  1182,    13,  2750, 18680,  8706,    11,   339,  2236,   281,\n",
       "           261,   307,  2636,  1320,   895,   270,  2788,   597, 14000,    11,\n",
       "           326,   314,   743,   766,     0,  9170,    68,  5052,   393,   584,\n",
       "          3818,    11,  1081,   996,   340,   547,   287,  1351,   274, 10611,\n",
       "           453,    13,  1279,  2327,    29,   770,  3175, 16487,  9373, 37205,\n",
       "            11,   843,   473,   485,    25,   366, 22788,    11,   644,   761,\n",
       "          2788,  1573,   274,  6941, 30960,   775,   423,   262,  1918, 20143,\n",
       "         10214,   258,   734,    11,  4930, 24486,   913,   266,  1186,  2052,\n",
       "           307,   356,    11,   290,  1275, 20288,    11,  1406,  1577,   514,\n",
       "          6159, 17703,  4249,  5473,    13, 50256, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "         50258, 50258, 50258, 50258, 50258]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the first two layers and 4 hidden units\n",
    "for name, param in model_poem.named_parameters():\n",
    "    if name.startswith(\"transformer.wte\"):\n",
    "        param.requires_grad = False\n",
    "    if name.startswith(\"transformer.wpe\"):\n",
    "        param.requires_grad = False\n",
    "    if any(x in name for x in ['.' + str(x) + '.' for x in range(5)]):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight False\n",
      "transformer.wpe.weight False\n",
      "transformer.h.0.ln_1.weight False\n",
      "transformer.h.0.ln_1.bias False\n",
      "transformer.h.0.attn.c_attn.weight False\n",
      "transformer.h.0.attn.c_attn.bias False\n",
      "transformer.h.0.attn.c_proj.weight False\n",
      "transformer.h.0.attn.c_proj.bias False\n",
      "transformer.h.0.ln_2.weight False\n",
      "transformer.h.0.ln_2.bias False\n",
      "transformer.h.0.mlp.c_fc.weight False\n",
      "transformer.h.0.mlp.c_fc.bias False\n",
      "transformer.h.0.mlp.c_proj.weight False\n",
      "transformer.h.0.mlp.c_proj.bias False\n",
      "transformer.h.1.ln_1.weight False\n",
      "transformer.h.1.ln_1.bias False\n",
      "transformer.h.1.attn.c_attn.weight False\n",
      "transformer.h.1.attn.c_attn.bias False\n",
      "transformer.h.1.attn.c_proj.weight False\n",
      "transformer.h.1.attn.c_proj.bias False\n",
      "transformer.h.1.ln_2.weight False\n",
      "transformer.h.1.ln_2.bias False\n",
      "transformer.h.1.mlp.c_fc.weight False\n",
      "transformer.h.1.mlp.c_fc.bias False\n",
      "transformer.h.1.mlp.c_proj.weight False\n",
      "transformer.h.1.mlp.c_proj.bias False\n",
      "transformer.h.2.ln_1.weight False\n",
      "transformer.h.2.ln_1.bias False\n",
      "transformer.h.2.attn.c_attn.weight False\n",
      "transformer.h.2.attn.c_attn.bias False\n",
      "transformer.h.2.attn.c_proj.weight False\n",
      "transformer.h.2.attn.c_proj.bias False\n",
      "transformer.h.2.ln_2.weight False\n",
      "transformer.h.2.ln_2.bias False\n",
      "transformer.h.2.mlp.c_fc.weight False\n",
      "transformer.h.2.mlp.c_fc.bias False\n",
      "transformer.h.2.mlp.c_proj.weight False\n",
      "transformer.h.2.mlp.c_proj.bias False\n",
      "transformer.h.3.ln_1.weight False\n",
      "transformer.h.3.ln_1.bias False\n",
      "transformer.h.3.attn.c_attn.weight False\n",
      "transformer.h.3.attn.c_attn.bias False\n",
      "transformer.h.3.attn.c_proj.weight False\n",
      "transformer.h.3.attn.c_proj.bias False\n",
      "transformer.h.3.ln_2.weight False\n",
      "transformer.h.3.ln_2.bias False\n",
      "transformer.h.3.mlp.c_fc.weight False\n",
      "transformer.h.3.mlp.c_fc.bias False\n",
      "transformer.h.3.mlp.c_proj.weight False\n",
      "transformer.h.3.mlp.c_proj.bias False\n",
      "transformer.h.4.ln_1.weight False\n",
      "transformer.h.4.ln_1.bias False\n",
      "transformer.h.4.attn.c_attn.weight False\n",
      "transformer.h.4.attn.c_attn.bias False\n",
      "transformer.h.4.attn.c_proj.weight False\n",
      "transformer.h.4.attn.c_proj.bias False\n",
      "transformer.h.4.ln_2.weight False\n",
      "transformer.h.4.ln_2.bias False\n",
      "transformer.h.4.mlp.c_fc.weight False\n",
      "transformer.h.4.mlp.c_fc.bias False\n",
      "transformer.h.4.mlp.c_proj.weight False\n",
      "transformer.h.4.mlp.c_proj.bias False\n",
      "transformer.h.5.ln_1.weight True\n",
      "transformer.h.5.ln_1.bias True\n",
      "transformer.h.5.attn.c_attn.weight True\n",
      "transformer.h.5.attn.c_attn.bias True\n",
      "transformer.h.5.attn.c_proj.weight True\n",
      "transformer.h.5.attn.c_proj.bias True\n",
      "transformer.h.5.ln_2.weight True\n",
      "transformer.h.5.ln_2.bias True\n",
      "transformer.h.5.mlp.c_fc.weight True\n",
      "transformer.h.5.mlp.c_fc.bias True\n",
      "transformer.h.5.mlp.c_proj.weight True\n",
      "transformer.h.5.mlp.c_proj.bias True\n",
      "transformer.ln_f.weight True\n",
      "transformer.ln_f.bias True\n"
     ]
    }
   ],
   "source": [
    "# now check layers\n",
    "for name, param in model_poem.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shayne Kaiser\\anaconda3\\envs\\poetryproject\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 111064\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 111064\n",
      "  Number of trainable parameters = 7089408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9dd6f3038d4b22b42e3ef9b879f5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111064 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3947, 'learning_rate': 4.550218812469609e-05, 'epoch': 0.09}\n",
      "{'loss': 1.3105, 'learning_rate': 4.09998739352027e-05, 'epoch': 0.18}\n",
      "{'loss': 1.3076, 'learning_rate': 3.6497559745709296e-05, 'epoch': 0.27}\n",
      "{'loss': 1.2994, 'learning_rate': 3.19952455562159e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/PoemDistil\\checkpoint-50000\n",
      "Configuration saved in ./Models/PoemDistil\\checkpoint-50000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2903, 'learning_rate': 2.7492931366722495e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Models/PoemDistil\\checkpoint-50000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2875, 'learning_rate': 2.2990617177229094e-05, 'epoch': 0.54}\n",
      "{'loss': 1.2864, 'learning_rate': 1.8488302987735697e-05, 'epoch': 0.63}\n",
      "{'loss': 1.2792, 'learning_rate': 1.3985988798242298e-05, 'epoch': 0.72}\n",
      "{'loss': 1.2837, 'learning_rate': 9.483674608748897e-06, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./Models/PoemDistil\\checkpoint-100000\n",
      "Configuration saved in ./Models/PoemDistil\\checkpoint-100000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2817, 'learning_rate': 4.981360419255498e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./Models/PoemDistil\\checkpoint-100000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2761, 'learning_rate': 4.790462297620977e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 6025.1475, 'train_samples_per_second': 18.433, 'train_steps_per_second': 18.433, 'train_loss': 1.2994928379906519, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=111064, training_loss=1.2994928379906519, metrics={'train_runtime': 6025.1475, 'train_samples_per_second': 18.433, 'train_steps_per_second': 18.433, 'train_loss': 1.2994928379906519, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trainer(model=model_poem,  args=training_args, train_dataset=train_dataset, \n",
    "        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                              'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                              'labels': torch.stack([f[0] for f in data])}).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./Models/PoemDistil\\config.json\n",
      "Model weights saved in ./Models/PoemDistil\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save model and Tokenizer\n",
    "model_poem.save_pretrained(\"./Models/PoemDistil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./Models/PoemDistil\\tokenizer_config.json\n",
      "Special tokens file saved in ./Models/PoemDistil\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./Models/PoemDistil\\\\tokenizer_config.json',\n",
       " './Models/PoemDistil\\\\special_tokens_map.json',\n",
       " './Models/PoemDistil\\\\vocab.json',\n",
       " './Models/PoemDistil\\\\merges.txt',\n",
       " './Models/PoemDistil\\\\added_tokens.json',\n",
       " './Models/PoemDistil\\\\tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_poem.save_pretrained(\"./Models/PoemDistil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in saved model and tokenizer \n",
    "tokenizer_poem = AutoTokenizer.from_pretrained(\"./Models/PoemDistil\")\n",
    "model_poem = AutoModelForCausalLM.from_pretrained(\"./Models/PoemDistil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: In view of the fading animals\n",
      "0:  In view of the fading animals' memory, Weigh in, that, with that they'd passed The bright moon that never came, Nor from heaven, nor their moon in one land-- Nor from his house in the field of dreams to the night's light, Which was made him more, in heaven or in Paradise-- As by the ways, though he could be no mortal, Which came not like thee? It seemed he only had a mind Which should have been no mortal for;--for he lived,--who now, and still He made, to sleep, who sleep. There the thought took off-- And soon he came again as the sea, Where are he? His footsteps have pierced him, I go, when to sleep The waves have run along the sea's banks; He went with them, he left them here, To wake me and me--for what I said. He went a journey by walking in all the air, In that sea I wandered there; In that sea I never went, Where should my soul's will be, If which a word to make, or sound That say would come, in the ocean that I never heard. There were, indeed my mind, and these dreams seem'd To hear them again In the sea we passed:\n",
      "1:  In view of the fading animals heark to the earth That, in which each life itself hath found, Is not too much to learn or can live in, But for we, so close unto life, Have seen or saw our selves, Who look or look through what nature hath done. For each soul Is that not too much for all that does take place, And for none of the ways is done: We do have nothing more Than these being, but to make the wise eye perceive, Of this reason to all others, is such a reason in ourselves to have any interest, Yet not the kind, if of the kind. But for a whole number of things the universe has got of nature and human nature have been brought with It in, and all are that; yet that no man, who loves to the most for which It has given to it, Has brought about its kind from itself.  One from one and the other in this life, that God sent him. 'But why?' it asks, I would not mind.  We could have said of it when I found it when I read Thee from its depths, But 'tis so difficult to do my work\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model_poem, tokenizer_poem,\"In view of the fading animals\", temp=1.5, num_outputs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Shall I compare thee\n",
      "0:  Shall I compare thee, or say with thy soul as to what man. So will no man. In the world it was not in this same age, Then did my Father be of some great thing, Yet did man have no life beyond the reach Of his very bosoms. I must have thought about how we saw the other; For one of our fathers said to his mother's door In an unknown hour as to whom she fell:  but thou dost say Thy words which my mother cried on.\" And so long he dost say,--I cannot but say of thee \"Take me into this house and thou wouldst not: Thou shalt no man stand alone And my only way I might live.\" He said unto my father,\n",
      "1:  Shall I compare thee with him to whom thyself will suffer, O I see His mercy, The holy God, the divine, the living; My love shall be as great as ever, O I shall bear his Son in mine! He will be with Him there in that world, for my God Has sent her to bless me. 'Tis yet more a little to love: O thou may think it are my heart to love thy heart. Thou art not such as a man to me, Who love is such as Christ, as mine can only share To what it was meant, to him which he belongs. But all you need a thing of love for? Let the people call their God one. His only need is all alone,\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model_poem, tokenizer_poem,\"Shall I compare thee\", temp=1.5, num_outputs=2, max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness\n",
      "0:  Deep into that darkness there he sat upon the tree That lies where it fell Upon a mountain which spilt. Now, after night a great tree was cast Down into hell, Through its darkened hollows and gray vines That rose, for its sake the fruit and fruit it fell Where it fell Its fruit hung on its branches above. And on that dark, I heard a long, long way passing, That I hear it through its open wide open open sky, On some hill of grass and with the snow It rose that broke its leaves where it fell. Then, on certain part it floated Through the narrow and flat blackness In the snow and snow, I could not breathe. It flew over and I saw its beauty with eyes; On that dark dark, in its coldness Its beauty. And now here it fell A great leaf as a shadow that spread Over the sky! Where is the leaf that lay Here? A hollow leaf of snow from below it! It was born with it a heart, a blood and blood-pleas'd tree, To a dead earth its own kind and death.  Where it came that rose stood Its own hand Where, while its wings were torn in thin streams,\n",
      "1:  Deep into that darkness the great-sail, the withering tide and the dead-star? For once the sun comes down on him to stand As though in the midst where, from her pale-green face To whose face were white as mine eyes? My lips must feel hers-- I hear, \"Behold, and let him say no; Your will will do, not for one night have me dead. Do you hold dear all of eternity!\" Oh! a cry--and, oh, oh, wait! he speaks softly--and, sweet is such a voice That whispers softly upon thee from the heart and the heart, To whom we speak of you? O, my children! they cry, As they are dying by-night!-- It was my heart. When will I die for a while To whom my tears grow from our lips on them? O--who knows. The mother sleeps--for her child I must sleep! O, my own mother sleeps? 'tis too late for him!-- The old man sleeps. Oh is it, dear, to my boy!-- O that is all it takes is enough pain In his love for me.\" So will I lay in your place, and give my life As though in the midst where, over at the top, As if it were near her. How soon the earth hath been so dark I feel that by my will And my love will no longer remain. O, the man that you love not I!\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model_poem, tokenizer_poem,\"Deep into that darkness\", temp=1.5, num_outputs=2, max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I\n",
      "0:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I thought, and I answered, \"What should be!\" and I asked, \"A mother so old and so ill! Do you know your face and this? It is not my mother!\" I replied again, \"I cannot know for you I only know! I cannot tell if it is her heart, because he's not at your hands; And if you can do your best, He's not at the heart.\" My father's face was wide awake, so all my heart was dark That had grown green And the sea trembled as the wind blew My mind away, and the dawn of night I spoke. And I said: 'Look, God, how I do not have her face that she gave you, and she told me, Thou art to dream on the ground.\" Little boy, as you see\n",
      "1:  Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I stood still and prayed: No words she did not write, None ever would but love It. I had lost my dream with these words, Who will have dreamed it a day. My soul did but her soul did not see my soul of flesh be in the night? Then she, sitting on a golden couch and playing the \"Lord,\" began weeping, And with tears a thousand years down on her lip did cry Out her love for me; He, whose heart with tears he kept, had loved to tell Of love as his love was not. For one's soul has made this day. There are no words for mine;\n"
     ]
    }
   ],
   "source": [
    "long_prompt = 'Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I'\n",
    "\n",
    "generate_from_model(model_poem, tokenizer_poem, long_prompt, num_outputs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs for: Finally finished\n",
      "0:  Finally finished with me to see them grow: And they all did so with delight and their good faces. It's all we can say: And then he gave you their gifts in my bosom; I wish them no care. But a dream was born in his bosom and full-blown, And a child, my heart beat fast to the ground, And in the bosom gave you life for him, with full grace. O baby of your love is yours all too strong as your mother; As you had your parents from me. But I had you on board a young life-long journey That led in you and my sister--no one came so near the world To greet the people, to make your mother happy again. It was me; but a child I had seen that had grown and grow-- And a daughter born into your bosom was a friend of hers. She was a man born from the bosom, an equal time with the mother's own. O son from the bosom! A beautiful baby from a sweet child is such a dear man-- For every life you live, he gave for me, for it brought and made, O baby of your love and the happy child.\" I came upon a very day old, And the little man\n",
      "1:  Finally finished, I'd had I in hand, nor should I; yet of me and my friend Eurydice, On my feet she cried, and when she fell, She cried;--I, my dear wife, you are a poor woman: Her tears are cold as snow and snow; For she's dead with me in the house.\" As from their great height The great black widow was there A day, while upon him the dead mother cried: \"My dear friend's will of the child Was so little. It's not the father's sake: We'd not take it, our life, Our home, not to take. But if she could bring some water we never should live.\"  'No, no, no!\" She exclaimed softly:--\"But why should so many children not? Why should children be so poor And, though the black mother died, A little is for us.\" To which the Mother's daughter reply--\"No. and so much not: If we may, I beg your hand,--I will be, 'for us,' I have not been--yet, as you go;--and with such eyes as we come\n",
      "2:  Finally finished she, like I've read for too long Now with this, that we need not long To turn me over for fear! If we had done all We could have done, then we should; We were all over again. My hope! This book has helped me greatly to hear What might I have called:\n",
      "\"All those that do speak out about love and love? Is life so miserable and sorrowing; It has caused men great problems.\" From the page to the foot goes The only real lesson we may learn About Love is our faith and devotion, and our joy-- \"That I shall learn from life.\" One could have found out The gospel, so clear and sweet indeed The faith and devotion that it teaches, Had passed out the soul for all men in Heaven. The light and all that glory in heaven hath lifted away our need For the whole world, and that heaven will soon learn. In short all this will be spent On good works, and in vain-- \"Heaven's dead, he has lived.\" \"I, as it was true, never saw the light\" It would now behove Him if we'd done things; \"That God's death is good work, That God's death is good!\n",
      "3:  Finally finished the time they've met and it looks so good. There's one great part, if done, the world,-- But we never made you feel we have too long. \"You see these eyes,\" And when one asks how this the world looks on in the old earth? Not yet, but the sight of them... A beautiful way of finding out How love is a great way of putting our lives into one beautiful place-- And even one thing that, dear, seems to hold-- And to our very sight they'll not even be there. You could go in with little sleep without seeing the way in a hundred shades and ten. 'Dee-deee--die'-n--that can never be true! The people would never know it-- But with great pain you have grown To meet a thing so good It does not get far from being old;\n",
      "4:  Finally finished her life In a strange place, my child's dream; And he would live and grow-- And, for this was, the night he made me-- All these months were spent; For the long summer, with all night spent he'd leave. Here was the dawn I slept in-- To rest her for this time was one to stay A lonely little boy; Yet now-- he went, \"I was coming not this morning-- To see me now And I went away by a long ago.-- The stars that were around me were not blue and yellow; And all are night or day and day again. A friend must be here again A distant little boy was a quiet place-- The white girl was no stranger There was an old girl -- The night and day again a little girl in the streets Of the land of the hills of England-- I walked across to a home so cold-tempered and lonely, It was one of my most difficult childhood: And her mind soiled I thought of walking back. For she and she was young and young, And the mother was young--\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(model_poem, tokenizer_poem,\"Finally finished\", temp=1.5, num_outputs=5, max_length=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('poetryproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed33b6c83ed5036cd92c69b03bba619a7b3d4b7bbbfa1b7f16f401f486e9f1b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
