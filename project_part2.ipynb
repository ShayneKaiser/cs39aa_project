{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts that will be used to generate text\n",
    "prompts = [\n",
    "    \"In view of the fading animals\", \n",
    "    \"Shall I compare thee\",\n",
    "    \"Deep into that darkness\"\n",
    "]\n",
    "\n",
    "long_prompt = 'Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I'\n",
    "\n",
    "# lines from poems: \n",
    "# They are hostile nations by Margret Atwood\n",
    "# Sonnet 18 by William Shakespeare\n",
    "# The Raven by Edgar Allen poe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the given prompt, must be one string, and generate output from the mode.\n",
    "def generate_from_model(prompt, max_length=30, temp=1.5, num_outputs=5):\n",
    "    \"\"\"\n",
    "    Tokenize the given prompt, must be one string, and generate output from the model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input string that is used to generate text\n",
    "        max_length (int): Max character length of the generated outputs\n",
    "        temp (int): Set the temperature for the outputs\n",
    "        num_outputs (int): number of different outputs to be created\n",
    "        \n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    \n",
    "    prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "    outputs = model.generate(inputs, max_length=max_length, do_sample=True, top_p=0.95, top_k=50, temperature=temp, num_return_sequences=num_outputs)\n",
    "\n",
    "    for i in range(len(outputs)):\n",
    "        generated = tokenizer.decode(outputs[i])\n",
    "        print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilGPT2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in tokenizer and model\n",
    "MODEL_NAME = \"distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token # add padding token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In view of the fading animals we should consider more often and for different reasons.\n",
      "\n",
      "There is an increase in the rate of animal killings from 1997\n",
      "In view of the fading animals in the field. All these other creatures look nothing like living creatures, and their status is uncertain.\n",
      "\n",
      "\n",
      "\n",
      "These\n",
      "In view of the fading animals in the forest, but the evidence indicates that the humans and animals living on these areas (Cockett, 1992).\n",
      "In view of the fading animals that surround you, make up their surroundings, provide support for people who rely on the kindness of nature.\n",
      "\n",
      "\n",
      "\n",
      "In view of the fading animals being replaced by a growing army, and also of them being destroyed to a new variety or new number. The modern movement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee and her with those whose lives and lives are divided in love.\n",
      "Dylan\n",
      "How would one like to be in love\n",
      "Shall I compare thee into these, all my own, that has arisen unto all the angels within me;\n",
      "But thou wilt up also unto\n",
      "Shall I compare thee with me and thou with mine.\" ~Jealous, he said with great effect; He was my father: He had been\n",
      "Shall I compare thee, My heart I say;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "There was also, as a great, glorious place. With it\n",
      "Shall I compare thee with an elephant! Do as well for as\n",
      "\n",
      "I look down to every single girl\n",
      "What is the beauty of that\n",
      "Deep into that darkness.\" He said, in a silent smile—\"Are you awake for what would make us so bad when all of my life are\n",
      "Deep into that darkness?\n",
      "Sidney's new biography, about Robert Kagan, explains the role of William Dreyfus, a famous\n",
      "Deep into that darkness, he heard the voice of a witch named Anna. 'It's not for me,' he muttered.\"\n",
      "\n",
      "With each new\n",
      "Deep into that darkness—at times in life and in death—are some simple decisions. As one will discover, we seek to achieve their greatest triumph\n",
      "Deep into that darkness, I heard a chorus from an earful. As you would expect, the way he moved toward you, he turned the page\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prompts)):\n",
    "    generate_from_model(prompts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep into that darkness peering, Long I stood there, wondering, fearing, Doubting, dreaming dreams no mortals Ever dared to dream before; But the silence was unbroken, And the stillness gave no token, And the only word there spoken Was the whispered word, \"Lenore!\" This I remembered once at the door of the cabin. He whispered softly his voice in her ear through that doorway. The two stared to hear it before finally turning around. It felt so strange, And\n"
     ]
    }
   ],
   "source": [
    "generate_from_model(long_prompt, max_length=100, num_outputs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('proenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9d1c7e630fdd03980df847aef2a95446cfda3da5074eddac844064b8ff5f9ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
